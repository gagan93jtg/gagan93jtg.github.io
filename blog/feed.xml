<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://gagan93.me/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://gagan93.me/blog/" rel="alternate" type="text/html" /><updated>2024-04-19T13:01:07+05:30</updated><id>https://gagan93.me/blog/feed.xml</id><title type="html">Gagandeep Singh — Blog</title><subtitle>Posts on Engineering, Culture, Leadership</subtitle><entry><title type="html">Titles, Inflation and Down-levelling</title><link href="https://gagan93.me/blog/2024/04/19/titles-inflation-downlevelling.html" rel="alternate" type="text/html" title="Titles, Inflation and Down-levelling" /><published>2024-04-19T00:00:00+05:30</published><updated>2024-04-19T00:00:00+05:30</updated><id>https://gagan93.me/blog/2024/04/19/titles-inflation-downlevelling</id><content type="html" xml:base="https://gagan93.me/blog/2024/04/19/titles-inflation-downlevelling.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2024-04-19-title-inflation-downlevelling.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-by-jason-strull-on-unsplash&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@jasonstrull?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Jason Strull&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/man-holding-his-head-while-sitting-on-chair-near-computer-desk-KQ0C6WtEGlo?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;If you’re confused about career ladders in different organisations, then this post will help you understand semantics of job titles (or job roles, or designations, or levels). There are many stories out there where people switch from a large service-based company to a product company (or one of the FAANG companies) where their titles are different or down-levelled. If you don’t have this understanding, you might think - &lt;em&gt;Why would someone move from a current role of Tech lead to a Senior Software Engineer&lt;/em&gt;?&lt;/p&gt;

&lt;h2 id=&quot;understanding-titles&quot;&gt;Understanding Titles&lt;/h2&gt;

&lt;p&gt;Titles are not standard across companies. And the reason is very obvious - you could open your own company and call yourself a Director/CEO. That might not have any significance unless you have some clients who pay you for the services you provide. As the company grows, you hire more people and/or get more customers. Only then the titles start making some sense. Applying the same example to the scenario where you might join a small company as a Founding engineer/Lead Engineer/VP of Engineering. Here, your initial title doesn’t matter because people in startups are &lt;a href=&quot;https://emeritus.org/blog/career-generalist-vs-specialist/&quot;&gt;generalists&lt;/a&gt;: You might be a Software developer by title but at times you could also be setting up servers, doing testing, and even doing customer support. Startups have flat hierarchy where most of the employees are less focussed on titles and more focussed on the mission.&lt;/p&gt;

&lt;p&gt;On the other end of this spectrum, we have medium to large organisations where leadership defines specific designations and salary bands. Here, people are very much concerned about their titles because their work and pay aligns with their bands. But that doesn’t mean that a Senior Engineer in one big tech does the same work and gets the same pay as the one working in another big tech. Although titles have a range of pay and not everyone on same title gets the same salary (even in a single company) but I hope you get what I’m saying - work and pay differs across companies. This is due to the variations in leadership styles, the complexity of work, and the specific skill sets and experience levels needed to attain a particular job title across different companies.&lt;/p&gt;

&lt;p&gt;The closest example in this concern is of my own. I work as a &lt;strong&gt;Staff Engineer&lt;/strong&gt; at &lt;a href=&quot;https://loconav.com/&quot;&gt;LocoNav&lt;/a&gt; that has a small engineering team of ~ 100 people. The complexity of my work is not at par with someone who is a &lt;strong&gt;Staff Engineer&lt;/strong&gt; at Google, Stripe, or Meta. So if I had to compare myself with a title in such companies, the closest one that aligns is of a &lt;strong&gt;Senior Software Engineer&lt;/strong&gt;. But the question is - how did I infer this, and how you can do the same for yourself?&lt;/p&gt;

&lt;h3 id=&quot;understanding-levels&quot;&gt;Understanding levels&lt;/h3&gt;

&lt;p&gt;If you want to understand where you currently are w.r.t big tech organisations, simply search something like “Google Software Engineer levels” (or Meta, or Uber). There are many articles already written by ex-employees that describe the responsibilities and expectations of each level. You can match the same with your current responsibilities and understand your level. This is helpful, specially if you’re targeting a role at that company.&lt;/p&gt;

&lt;p&gt;I hope the above explains something around titles.&lt;/p&gt;

&lt;h2 id=&quot;what-is-title-inflation&quot;&gt;What is Title Inflation?&lt;/h2&gt;

&lt;p&gt;There are some organisations that have a defined career ladder but you get promoted to the next level sooner. As an example, I’ve seen people in small companies that have title of &lt;strong&gt;Principal Engineer&lt;/strong&gt; which is a really senior technical position if we compare the same title to people in large organisations. This is majorly for two reasons:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Although the median tenure in the industry for software developers is ~ 4 years, there are people who do not change job for a 8-10 years. Organisations create new positions for such people so that they can be promoted (I’ve seen this myself). In small teams, people with ~ 10 years of experience could be Principal Engineers, while large organisations usually consider people in the range of 12-15 years eligible for this position (although exceptions are always there).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sometimes, organisations &lt;a href=&quot;https://en.wikipedia.org/wiki/Job_title_inflation&quot;&gt;inflate your title&lt;/a&gt; in order to retain you when you quit. This may or may not include a hike in your pay (based on your negotiation) but moves you to the next level. Not debating if this is right or wrong, fair or unfair but it is what it is :)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The second scenario is a typical case of title inflation. Advancing to the next level can boost your confidence, but it might not benefit you in the long term, especially if your current skills don’t align with that level. This situation could even lead to being down-levelled in your next position.&lt;/p&gt;

&lt;h2 id=&quot;down-levelling-explained&quot;&gt;Down-levelling explained&lt;/h2&gt;

&lt;p&gt;As the name suggests, it’s like getting a demotion (moving to a lower level). We need to understand when it actually concern us:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;If you’re in the same organisation and you’re getting down-levelled, then it might be a serious concern. You can talk to your manager to understand why this happened. If this is due to some performance concerns, then you might already be expecting this. Incase there is a major restructuring happening in the organisation and all the job roles are being redefined, this might be fine. It all depends on the situation and how you negotiate.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you’re moving to some other organisation, you must learn about their levelling (as already explained above). If you are getting down-levelled while changing the organisation, it might not be wrong because of different role expectations in the next organisation. Although in all cases, you must negotiate with the hiring manager and understand the expectation of next level to see if you can move to the next it :)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I hope this clears up any confusion about different companies and their job titles.&lt;strong&gt;.&lt;/strong&gt; It’s mostly about the organisation, their expectations, and their team’s size that defines the levels. If you’re moving to a different organisation and are being considered at a lower level, don’t get sad. Understand their job role expectations. At the same time, if you feel that you meet the expectations of a higher level, never settle for less.&lt;/p&gt;

&lt;p&gt;Thanks for reading.&lt;/p&gt;</content><author><name>Gagandeep Singh</name></author><category term="title" /><category term="title-inflation" /><category term="downlevelling" /><summary type="html">If you're confused about career ladders in different organisations, then this post will help you understand semantics of job titles (or job roles, or designations, or levels). There are many stories out there where people switch from a large service-based company...</summary></entry><entry><title type="html">Cloud, SaaS Cost Reduction</title><link href="https://gagan93.me/blog/2024/03/21/cloud-saas-cost-reduction.html" rel="alternate" type="text/html" title="Cloud, SaaS Cost Reduction" /><published>2024-03-21T00:00:00+05:30</published><updated>2024-03-21T00:00:00+05:30</updated><id>https://gagan93.me/blog/2024/03/21/cloud-saas-cost-reduction</id><content type="html" xml:base="https://gagan93.me/blog/2024/03/21/cloud-saas-cost-reduction.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2024-03-21-cloud-saas-cost-reduction.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-by-ussama-azam-on-unsplash&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@ussamaazam?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Ussama Azam&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/pink-arrow-neon-sign-26h317_UMYM?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Reducing spend on SaaS tools is a continuous effort. At LocoNav, we keep a strict eye on such expenses and spend some time every now and then to make sure we’re not paying extra for any service. In the past 1.5 years, we planned and executed a lot of tasks to reduce our spends. This included what we pay to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Cloud platforms,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Observability platforms,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Collaboration platforms,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;And other SaaS tool (eg. we use location related services heavily in our products as we’re a &lt;a href=&quot;https://loconav.com/&quot;&gt;fleet management product&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This task was taken up by multiple people including myself and we had to figure out our usage of each tool in a way that we can either optimise them or (possibly) replace them. So the thought process was broken into these categories:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Unused resources&lt;/strong&gt; - Are there unused resources lying that can be freed to save some 💰? This includes unused Github seats, a server that was mistakenly left running, a disk volume that’s lying unattached after terminating a machine, etc.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Optimising Data volume&lt;/strong&gt; - Are there tools where we could send less data without impacting the usage? For example, you can control how much data is sent to APM tools and save some cost here because general trend still remains (almost) same and they bill you for the amount of data you send.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Finding alternative tools&lt;/strong&gt; - Are there tools that can be replaced with cheaper or open source (self-hosted) alternatives?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Architectural optimisations&lt;/strong&gt; - Can we plan short term and long term architectural changes that would help us save cost? We knew a few things that could be architected better. So we prioritised tasks in a way that have high ROI in the short term were picked first while others were parked for the long term.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The above thought process looks very structured. Frankly, we did not start like this but this is how it eventually turned out to be.&lt;/p&gt;

&lt;h2 id=&quot;figuring-out-everything&quot;&gt;Figuring out everything&lt;/h2&gt;

&lt;h3 id=&quot;unused-resources&quot;&gt;Unused resources&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SaaS platforms&lt;/strong&gt; - Most of the SaaS applications have pricing based on no. of users. While onboarding new team members is a usual activity and happens sooner or later, but it’s equally important to offboard them once they leave. In small teams, this leak often remains undetected for months. Beyond cost, this could have other risks unless the user logs in through SSO. So make sure to deactivate accounts and free those seats when users leave. It might have a small impact on monthly bills but it is important to have a complete list of apps where you need to deactivate user accounts.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cloud platforms&lt;/strong&gt; - It’s hard to accurately understand and justify cloud spends but members of the team should still have an idea on how many databases, virtual machines and other cloud resources they’re using. If you have a single cloud account that multiple teams use, I’d recommend you to &lt;a href=&quot;https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html&quot;&gt;tag the resources&lt;/a&gt; used by respective teams. Once done, it becomes easy to discuss and optimise the cost for each team. Beyond this, you could figure out things that are not used or could be combined. For example, we figured out and did all this:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Buckets&lt;/strong&gt; - Check unused S3 buckets and deleted them. Modified storage class for a few of them and set intelligent tiering to a few.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;EC2/EBS&lt;/strong&gt; - We moved to EKS for many apps so we deleted &lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html&quot;&gt;AMIs&lt;/a&gt; for those apps, that helped us free up a lot of space used by snapshots. Apart from this - basic optimisation like deleting unused machines that were left mistakenly, checking instance usage and resizing machines were also done.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Merging few deployments&lt;/strong&gt; - There were a lot of small projects (both internal and customer facing) which used individual databases, caches and machines. We consolidated databases for a lot of internal tools on a single RDS that still didn’t peak to even 50% of CPU after combining. Thankfully all our relational use cases are on Postgres that helped in this consolidation (read about &lt;a href=&quot;https://blog.gagan93.me/avoid-redundant-complexity&quot;&gt;embracing simplicity&lt;/a&gt;). This was planned for some other projects also that were customer facing but very much related to each other and could be combined.
 Note: Don’t overdo this as this has one potential downside - incase you upgrade this RDS in future in a way that it needs a downtime, you’d need to take downtime on all the apps that use this RDS.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;optimising-data-volume&quot;&gt;Optimising data volume&lt;/h3&gt;

&lt;p&gt;Before understanding what we optimised, I’ll share some background on data transfer (ingress and outgress) costs. Data transfer is one of the most trickiest component in a cloud provider’s bill. For many managed resources, you pay for the amount of data transferred through them (apart from the basic cost of running them). &lt;a href=&quot;https://aws.amazon.com/elasticloadbalancing/pricing/&quot;&gt;AWS load balancer&lt;/a&gt; is a perfect example of this where you pay a monthly cost of using it and another cost for the amount of data transferred. Even beyond this, if the data goes out to the public internet (outside AWS) or a &lt;a href=&quot;https://aws.amazon.com/about-aws/global-infrastructure/regions_az/&quot;&gt;different region&lt;/a&gt;, you get charged extra. The data transfer cost is negligible for personal projects / small apps but it becomes a considerable part of your bill if your apps have a lot of data flowing outside the AZ/Region. The point is - how do I know if the data goes out of cloud provider 🤔? The answer is not so simple and it varies from &lt;a href=&quot;https://babatrucks.atlassian.net/browse/INTAKE-7424&quot;&gt;one provider&lt;/a&gt; to &lt;a href=&quot;https://azure.microsoft.com/en-in/pricing/details/bandwidth/&quot;&gt;another&lt;/a&gt;. As a thumb rule, assume you’ll be charged for data if:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;It goes out of your AZ (availability zone) or region.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You connect to a service that runs on another cloud provider (or generally on public internet).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Coming back to optimising data volume - We use Datadog for Application Performance Monitoring (APM). Some of our large applications send a lot of data to Datadog. If you check their &lt;a href=&quot;https://docs.datadoghq.com/account_management/billing/pricing/#apm&quot;&gt;APM billing&lt;/a&gt;, you’ll realise that they consider &lt;em&gt;amount of spans ingested&lt;/em&gt; for charging the user. Because the data can be very large for mid-large applications, they give an &lt;a href=&quot;https://docs.datadoghq.com/tracing/guide/ingestion_sampling_use_cases/#reducing-ingestion-for-high-volume-services&quot;&gt;option to control&lt;/a&gt; how much percentage of data we want to sample. This reduces costs in two ways: data received at the APM layer is lower (hence less bill) and data emitted from our system is also less (hence less transfer charges). Here, the data transfer cost would impact us only if Datadog’s infrastructure is deployed in a different AZ/Region/Cloud provider. As of March 2023, when someone &lt;a href=&quot;https://www.linkedin.com/pulse/datadog-outage-multi-cloud-reliability-dylan-ratcliffe/&quot;&gt;unofficially investigated&lt;/a&gt; Datadog’s outage, he found out that Datadog uses multi-cloud deployment strategy, i.e. they deploy in AWS, Azure and GCP. So you can believe that your data is most probably going out of the cloud provider.&lt;/p&gt;

&lt;p&gt;For your apps - If you start with this basic knowledge of ‘how your cloud provider charges for data transfer’, you can optimise a few things on the bill 😀.&lt;/p&gt;

&lt;h3 id=&quot;finding-alternative-tools&quot;&gt;Finding Alternative tools&lt;/h3&gt;

&lt;p&gt;This was a medium-hard problem because shifting people to a new tool is hard. Being a team of ~ 100 software engineers, we use a lot of industry standard tools like APM tools, error trackers, server and website monitoring tools, communication tools and what not. We moved from NewRelic to Datadog for APM back in 2021 (due to cost reasons) and I remember the switch was not easy. While both are very good tools and best in industry, we were habitual of using NewRelic for debugging our slowness and outage cases. It took some time to adjust to Datadog’s features and UX and now we find it quite useful to debug such cases (specially the &lt;a href=&quot;https://docs.datadoghq.com/monitors/types/watchdog/?tab=apm&quot;&gt;Watchdog&lt;/a&gt; feature 👌). Still we tried to find alternate platforms for whatever was possible to replace and started using &lt;a href=&quot;https://www.getoutline.com/&quot;&gt;this tool&lt;/a&gt; for documentations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Can you also do this ? -&lt;/strong&gt; It depends on how much your team is flexible in moving to the new tool. It also depends on the pricing model of your current tool. Like if you’ve already committed or paid for next few months or an year, then you could defer the plan to move. But always try to use tools that allow exporting data into common (non-proprietary) formats. For example, although JIRA is a industry standard tool for managing team sprints, there is &lt;a href=&quot;https://community.atlassian.com/t5/Jira-Software-questions/How-to-export-Jira-issues-to-CSV/qaq-p/175115&quot;&gt;no way to export all the issues&lt;/a&gt; as CSV. The best answer on this community post allows to export max 1000 issues at once. Although importing data to JIRA is easy and explained &lt;a href=&quot;https://support.atlassian.com/jira-cloud-administration/docs/migrate-from-other-issue-trackers/&quot;&gt;here&lt;/a&gt; 🤓.&lt;/p&gt;

&lt;h3 id=&quot;architectural-optimisations&quot;&gt;Architectural optimisations&lt;/h3&gt;

&lt;p&gt;These optimisations majorly depend on your own project. For medium-large projects that are live in production from years, the teams are already aware of tech debt and architectural debt. Beyond debt, there could be technological advancements that you can leverage. As an example, Redis is a popular in-memory key-value database. The initial version of Redis was released almost 15 years ago. While there have been a lot of changes and features additions even recently, the basic architecture of command processing remains the same - a single threaded command execution thread. Don’t underestimate the speed of Redis after reading &lt;em&gt;single threaded.&lt;/em&gt; While Redis works well for applications of all sizes, there have been a lot of choices now, as Paypal open sourced it’s &lt;a href=&quot;https://github.com/paypal/junodb&quot;&gt;key value store&lt;/a&gt;, a team of developers released a new key value database called &lt;a href=&quot;https://www.dragonflydb.io/&quot;&gt;Dragonfly&lt;/a&gt; and Microsoft introduced &lt;a href=&quot;https://www.microsoft.com/en-us/research/blog/introducing-garnet-an-open-source-next-generation-faster-cache-store-for-accelerating-applications-and-services/&quot;&gt;Garnet&lt;/a&gt; this week. Not everyone wants to move their existing systems to new (promising) databases and you should actually never do that, but I was surprised to see a very stable and &lt;a href=&quot;https://github.com/sidekiq/sidekiq/commit/250cc1e4dde44e84d9b607a2ded84ec0835a3ef1&quot;&gt;popular Ruby library&lt;/a&gt; offering choice between Redis and DragonflyDB as a queueing backend for background jobs 😃.&lt;/p&gt;

&lt;p&gt;Developers rewrite systems all the time, but that choice is not always available. Even when allowed, large rewrites often fail to replace existing (stable) systems due to one or the other reason. To optimise our costs, we tried to rewrite parts of the systems that we were sure of. Some infrastructure changes also helped us save cost but that impacted our architecture and also how our team debugs production issues. We tried and did the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;We moved a lot of our applications to Kubernetes cluster. The apps were tested for more than an year on non production environments before moving. Using a combination of AWS on-demand and spot instances clubbed with Kubernetes’ &lt;a href=&quot;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/&quot;&gt;HPA&lt;/a&gt;, we were able to save on cloud costs. Spot instances helped us using same infra on a cheaper price, while some on-demand nodes balanced out for stability. HPA allowed us to turn off pods when load on the system was less (eg. at night).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We planned, tested and moved our ruby application server from a single threaded (&lt;a href=&quot;https://github.com/phusion/passenger&quot;&gt;passenger&lt;/a&gt;) to multi-threaded (&lt;a href=&quot;https://github.com/puma/puma&quot;&gt;puma&lt;/a&gt;). We had to validate thread safety of our code and third party libraries before doing this.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We refactored our &lt;a href=&quot;https://github.com/sidekiq/sidekiq&quot;&gt;background job server&lt;/a&gt; setup to lesser number of queues that simplified our deployment one EC2 and eventually on k8s. This also helped in saving cost as pods were getting utilised to their maximum extent and HPA scaling pods up and down as needed.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Other optimisations included rewriting a few systems, details of which cannot be shared (and also won’t be helpful to anyone). These were mostly long term optimisations.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;This was by no means a single person’s work. A lot of senior engineers and devops collaborated to plan and execute all these activities but the gains were rewarding and for the long term. These are recurring bills, so saving even $500 a month means saving $6000 annually. After seeing all these optimisations, I often think - &lt;em&gt;were we really wasting this much money per month&lt;/em&gt; 🤔? The answer for this might depend on the team/company. In a growing team, such scenarios often happen. New teams, new projects, new deployments can lead to some inefficiencies over time. Regular consolidations and some approval flow from centralised teams can help in reducing this. For teams that have dedicated people for optimising costs and ensuring efficient use of resources, these instances should be minimum. If you’re a team that has not yet focussed on optimising such costs, do try a few things mentioned here.&lt;/p&gt;

&lt;h1 id=&quot;bonus&quot;&gt;Bonus&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Budget alerts&lt;/strong&gt; - Many platforms allow setting alerts on user defined thresholds (&lt;a href=&quot;https://docs.github.com/en/billing/managing-billing-for-github-actions/managing-your-spending-limit-for-github-actions&quot;&gt;example 1&lt;/a&gt;, &lt;a href=&quot;https://aws.amazon.com/aws-cost-management/aws-budgets/&quot;&gt;example 2&lt;/a&gt;). You can set these up to catch anomalies in costs. We have some of these setup that often help us.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dedicated ownership -&lt;/strong&gt; Software teams rely on many tools. As the team grows, it’s hard for one person to keep a track of everything. At the same time, keeping a basic check on costs and anomalies doesn’t require a lot of expertise. If you assign some people to dedicatedly monitor some tools, it will not burden anyone and will ensure catching such leaks early.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Continuous monitoring&lt;/strong&gt; - In the past, we use to ignore a lot of platforms and were optimising only cloud bills. This was our first mistake as other bills were not negligible. Second mistake was to check for optimisations only a month before our reservations expired. Cost optimisation is not an annual activity. We should be continuously monitoring these costs.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;Thanks for reading. I hope this would help you to optimise some SaaS cost for your organisation. If you liked this post, do check out the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Make sure your stack is &lt;a href=&quot;https://blog.gagan93.me/cloud-pricing-vendor-lock-ins&quot;&gt;not vendor locked-in&lt;/a&gt; if you want flexibility of moving out in future (or maybe otherwise also)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A detailed post on &lt;a href=&quot;https://blog.gagan93.me/optimising-docker-builds&quot;&gt;optimising docker build time and build size&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Working in a team requires asking for help every now and then. Learn &lt;a href=&quot;https://blog.gagan93.me/asking-good-questions&quot;&gt;how to ask good questions&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Gagandeep Singh</name></author><category term="cloud" /><category term="saas" /><category term="pricing" /><category term="optimisation" /><summary type="html">Reducing spend on SaaS tools is a continuous effort. At LocoNav, we keep a strict eye on such expenses and spend some time every now and then to make sure we're not paying extra for any service. In the past 1.5 years, we planned and executed a lot ...</summary></entry><entry><title type="html">Developing From Scratch: 2016 vs. now</title><link href="https://gagan93.me/blog/2024/03/15/developing-from-scratch-2016-vs-now.html" rel="alternate" type="text/html" title="Developing From Scratch: 2016 vs. now" /><published>2024-03-15T00:00:00+05:30</published><updated>2024-03-15T00:00:00+05:30</updated><id>https://gagan93.me/blog/2024/03/15/developing-from-scratch-2016-vs-now</id><content type="html" xml:base="https://gagan93.me/blog/2024/03/15/developing-from-scratch-2016-vs-now.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2024-03-15-developing-from-scratch.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-by-brandspeople-on-unsplash&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@brandsandpeople?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Brands&amp;amp;People&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/person-writing-on-white-paper-Ax8IA8GAjVg?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;One year into the industry, I wasn’t sure if I knew enough about full-stack software development. I was working on a maintenance project, where we were mostly scaling down the system, doing small bug-fixes, doing a lot of debugging and writing a little bit of new code. I visited my college in 2016 where I met some juniors and the placement head. I discussed the idea of creating an Alumni website for our college because no such connection existed between the college and it’s alumni. While I was into full-stack development but I didn’t like doing frontend a lot. So I discussed the idea with my friend &lt;a href=&quot;https://www.linkedin.com/in/ekas/&quot;&gt;Ekas&lt;/a&gt; (a year junior to me and just out of college) and we both started working on it. This was completely out of fun, not for profit project. This was our tech stack at that time:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Backend&lt;/strong&gt; - Ruby on Rails,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Frontend&lt;/strong&gt; - JQuery/Bootstrap,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Database&lt;/strong&gt; - MySQL (all user data), Redis (for some caching, probably redundant),&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cloud provider&lt;/strong&gt; - Linode (Reason: Non fancy platform &amp;amp; straight forward billing),&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Issue tracker&lt;/strong&gt; - Trello,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Version control&lt;/strong&gt; - Gitlab initially (now Github, &lt;a href=&quot;https://github.com/gagan93jtg/gtbit_alumni/&quot;&gt;source code&lt;/a&gt;),&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Communication&lt;/strong&gt; - Gmail/Whatsapp,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Domain&lt;/strong&gt; - Godaddy,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;CDN&lt;/strong&gt; - Cloudflare (Wasn’t needed, but I needed a free SSL Cert that they provided).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Like many other side projects, the stack was pretty straight forward - We chose what the best we knew. For example, if I knew about &lt;a href=&quot;https://letsencrypt.org/&quot;&gt;LetsEncrypt&lt;/a&gt; for SSL certificate, I’d not have used Cloudflare because CDN was not required at that time.&lt;/p&gt;

&lt;h2 id=&quot;developing-something-in-2024&quot;&gt;Developing something in 2024&lt;/h2&gt;

&lt;p&gt;In past 8 years, software landscape has seen major changes. And with recent advancements in AI, we’re able to write code faster. Many low-code and no-code tools are also available if you need to build simple things (even beyond static websites). For example, I had to revamp my portfolio website from &lt;a href=&quot;https://gagan93.me/v2/&quot;&gt;this&lt;/a&gt; to &lt;a href=&quot;https://gagan93.me/&quot;&gt;current&lt;/a&gt; two months ago. It took me just a few hours to create the current version because the skeleton and design was &lt;a href=&quot;https://www.linkedin.com/posts/gagan93_some-good-prompts-on-chatgpt-helped-me-revamp-activity-7145825841346674688-4ssY&quot;&gt;generated by ChatGPT&lt;/a&gt;. As recent as this week, &lt;a href=&quot;https://www.youtube.com/watch?v=AgyJv2Qelwk&quot;&gt;Devin is released&lt;/a&gt;, who is world’s first AI Software Engineer (although a bold claim to make).&lt;/p&gt;

&lt;p&gt;Given all the improvements over time, let’s discuss the choices we have if you are (or even I am) developing an MVP or side project today:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Backend&lt;/strong&gt; - Although my major backend experience has been in Rails and it will be a biased opinion if I say Rails is faster to develop than any other framework. But I’ve seen many people and organisations use Rails to quickly build MVPs. So if I was building something that really needs a complete dynamic and full-stack website of it’s own (with UI), I’d still prefer Rails. If there’s a simpler requirement where I just need to develop APIs on the backend, and frontend is a mobile platform, I might be inclined to use serverless platform to start with. Reason for choosing serverless is simple - the deployment strategies are simpler and I’d pay for the time I’m using the backend, rather than running servers full-time. &lt;a href=&quot;https://docs.rubyonjets.com/&quot;&gt;Ruby on Jets&lt;/a&gt; is one such option if you’re a Rails developer. It’s just a wrapper over AWS Lambda, Gateway and databases. You can also use Lambda directly rather than using this fancy wrapper, and write your functions in Java, NodeJS, Python, Go and other &lt;a href=&quot;https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html#runtimes-supported&quot;&gt;platforms supported by Lambda&lt;/a&gt;. Another stack is very popular these days that uses Google Cloud services like Cloud functions as backend, Firestore as a NoSQL database. If you’re planning to use AWS, you might want to consider serverless databases like &lt;a href=&quot;https://aws.amazon.com/rds/aurora/serverless/&quot;&gt;Aurora Serverless&lt;/a&gt; (for SQL) and &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-elasticache-serverless/&quot;&gt;Elasticache Serverless&lt;/a&gt; (for Redis/Memcached) or the famous &lt;a href=&quot;https://aws.amazon.com/dynamodb/&quot;&gt;DynamoDB&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Frontend&lt;/strong&gt; - In the past 4-5 years, I’ve worked quite less on the frontend side. My project’s frontend is in ReactJS and I’ve never written code in it. For some internal portals and for my personal portfolio, I still get to work on HTML, CSS (sass), Bootstrap and Jquery. If I get someone to handle the frontend part, I might want to use React/Next/Vue on the frontend side with a modern CSS framework like Tailwind. But if I’m handling the frontend myself, I’d still use the old stack. It’s not that I don’t want to learn something new, but because I’d prioritise delivery speed over anything for the MVP. This is the single most important thing to consider when building MVP. &lt;strong&gt;Unless there’s a significant speed boost in using a new technology, don’t run towards it while validating your idea/product.&lt;/strong&gt; AFAIK, if I use a modern framework and write code in Typescript, I’d need a transpiler like webpack to convert it into JS code before deploying. And I’d not want to &lt;a href=&quot;https://blog.gagan93.me/avoid-redundant-complexity&quot;&gt;add more complexity&lt;/a&gt; in the beginning unless it’s worth.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Deployment / Hosting -&lt;/strong&gt; If you plan to use cloud functions / lambdas for your backend, you might not need any place to host your server. Your code could be deployed easily by the UI provided by the platform. Incase you’re still need to run your app server on a virtual machine, there are a few options like&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Deploying app directly on VM.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Deploying app as a container on VM (behind Nginx proxy maybe)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Deploying app as a container on managed platform (like AWS ECS)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Deploying app as a container on orchestration platform (like AWS EKS)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;If you don’t have experience with Docker or Kubernetes, just use the first option. it’s like deploying app on the server in the same way you’d setup on your local machine (with minimal differences). If you have experience with Docker and Kubernetes, still prefer to choose a service that’s cheap to start with. For example, you don’t need a full-blown EKS cluster to start with as it would cost $70-75 per month just to have the cluster running (while you could get a t4g.xlarge [4CPU / 16GB] machine in that cost). Given my expertise with containers and ease of deployment, I’d prefer 2nd or 3rd option.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Database&lt;/strong&gt; - I see a lot of new folks preferring NoSQL databases for all kinds of use cases. All new shiny tech looks good unless you fall face operational complexities. That being said, I’d prefer SQL database if following conditions are satisfied:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;The requirements enforce some relation between the entities (that can be easily modelled as foreign keys).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The data is not just append only (i.e. it probably needs updation).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;There are (probably) transactional requirements.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Even if 2/3 are true, it makes sense to use an SQL database. If not, you can go for a NoSQL database. There are many choices in both of these, which are already discussed in the first point.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cloud Provider&lt;/strong&gt; - If you’re having experience with any cloud provider and understand their billing well, choose them blindly (just kidding). Cloud billing is the most complex thing ever invented by these guys. I’ve seen people struggling on their personal account (with their own credit card) when they’re not able to understand what they’re getting billed for. Even if you sit with your project’s Devops team and ask them to explain the components of this month’s bill, I bet there will be parts they can’t explain completely. Discussing cloud bills is a complete topic on it’s own and the subject is so complex that there are dedicated companies that help you lower your cloud bill (eg. &lt;a href=&quot;https://www.duckbillgroup.com/&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;https://www.builder.ai/builder-cloud&quot;&gt;2&lt;/a&gt;). So if you have experience using AWS and you either understand their billing, or at least know how you can terminate everything and remove your credit card, then choose that provider. For your use case (i.e. an MVP), there won’t be huge difference in cloud costs. If you don’t have experience with cloud providers, do one of the following:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Choose any one provider, learn how to setup budget alerts and remove your credit card if something goes out of hands.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Find a dead simple one - I chose Linode because I had used it in my project and they gave only one service (plain unix VM). There was no additional service provided by them (like machine images, container hosting, security groups, load balancers) and hence billing was very simple. The server I ran back in 2016 costed me $10 per month (nothing more, nothing less).&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Issue tracker&lt;/strong&gt; - Use anything that’s free. You could even use google sheets to keep things simple.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Communication&lt;/strong&gt; - Whatsapp has grown into a very nice communication tool but nothing beats a tool like Slack 😍. I just checked that they provide a free plan with limited features and 3 month message history. If that works for you, spin a new slack instance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Version control&lt;/strong&gt; - Github is a popular choice here. I’d happily use it because they now allow private repos for free. So incase you’re building something that could grow into a paid product later, you’d want to keep your code private. I’ve used Gitlab and bitbucket also. Almost all of them support CI/CD setup incase you’re looking to have that for your project.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Domain&lt;/strong&gt; - You need a domain for your project unless you’re happy hosting as a subdomain of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.herokuapp&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.netlify&lt;/code&gt; . I have a few domains and I find Godaddy cheap for domains. You can compare providers and see whatever works for you. There’s nothing special with domain providers. There are ways to migrate from one provider to another (it takes 1-2 days) if you need to do that in future. Also, you can move DNS management (that routing thing) to some other provider if you want. So in my organisation, we have DNS on AWS Route 53 while domain management is with Godaddy. That’s doable if you need to do that in future.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;CDN&lt;/strong&gt; - I think to start with, I won’t need it unless I’m creating paid videos for my DSA/System Design course 🤣 (jokes apart: because videos are static resources that could be served fast using a CDN). If we need a CDN, we can choose between popular ones like Akamai, Cloudflare or AWS Cloudfront. I don’t have any strong opinions here.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More things? Of course, we did not talk about Load balancers, API Gateways, Firewalls and many other components. In most of the cases, you won’t need them when starting up. The idea was to outline the choices available today vs those available back then. There were lesser cloud providers with fewer services, Docker was fairly new, managed docker services were limited, and Linode was dead simple (and not owned by Akamai). While choosing your stack, just make sure you’re not too much locked into one provider. For example, while Google’s stack sounds simple and cheap to begin with, you’ll be locked with it completely if you build on it. It’s not impossible to migrate but it could be hard or expensive. Another example could be of AWS RDS - If you’re using a Postgres/MySQL database hosted on RDS, that doesn’t completely lock you with AWS as Postgres could be self hosted outside AWS also. But if you use something like DynamoDB, then you can’t move outside AWS unless you find an alternative, change your code and move all your data to the new datastore. If you write your code in a modular fashion and follow good design patterns (like a &lt;a href=&quot;https://refactoring.guru/design-patterns/facade&quot;&gt;facade&lt;/a&gt; over the classes that interact with DynamoDB), you could easily switch to new database. But if your code is coupled deeply, it could take time to refactor everything and &lt;a href=&quot;https://blog.gagan93.me/cloud-pricing-vendor-lock-ins&quot;&gt;take yourself out from AWS&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;As software developers, we often face &lt;a href=&quot;https://en.wikipedia.org/wiki/Impostor_syndrome&quot;&gt;imposter syndrome&lt;/a&gt; and feel like we don’t know nothing beyond our company projects. Building something in parallel could be a way to sharpen your skills and increase confidence. If you have time, you can build something in a new tech stack. If not, feel free to choose your existing stack and build it. Sadly, I got too busy with my work that I did not spare enough time to build anything else like the Alumni website. But thankfully I started writing last year and I enjoy that (I hope you too enjoy reading the blogs 😊).&lt;/p&gt;</content><author><name>Gagandeep Singh</name></author><category term="Development" /><category term="Scratch" /><category term="BuildingAndLearning" /><summary type="html">One year into the industry, I wasn't sure if I knew enough about full-stack software development. I was working on a maintenance project, where we were mostly scaling down the system, doing small bug-fixes, doing a lot of ...</summary></entry><entry><title type="html">Devops Essentials for Developers</title><link href="https://gagan93.me/blog/2024/03/05/devops-essentials-for-developers.html" rel="alternate" type="text/html" title="Devops Essentials for Developers" /><published>2024-03-05T00:00:00+05:30</published><updated>2024-03-05T00:00:00+05:30</updated><id>https://gagan93.me/blog/2024/03/05/devops-essentials-for-developers</id><content type="html" xml:base="https://gagan93.me/blog/2024/03/05/devops-essentials-for-developers.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2024-03-05-devops-servers.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-by-taylor-vick-on-unsplash&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@tvick?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Taylor Vick&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/cable-network-M5tzZtFCOfs?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;There are multiple definitions of the term &lt;strong&gt;DevOps&lt;/strong&gt; throughout the industry. I’ll share a few and then we’ll discuss more on them:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Philosophical definition (by AWS)&lt;/strong&gt;: DevOps is the combination of cultural philosophies, practices, and tools that increases an organisation’s ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organisations using traditional software development and infrastructure management processes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;In relation to code&lt;/strong&gt;: DevOps involves some coding, but it’s not primarily about writing code. It’s more about improving processes, collaboration, and automation in software development and IT operations. While coding is essential for creating automation scripts and tools, it’s just one aspect of DevOps.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;As a career / job profile&lt;/strong&gt;: Depending on kind of organisation, there might be different expectations. A decade ago, the work was more around physical server administration when the Devops team was responsible for handling physical servers (and later, cloud servers). In the recent years, most of the organisations have delegated the server administration to cloud providers. And the expectations have shifted to knowledge of technologies like &lt;strong&gt;Containerization&lt;/strong&gt; (Docker, Kubernetes), &lt;strong&gt;Observability&lt;/strong&gt; (Grafana, NewRelic, Datadog), &lt;strong&gt;IaaC&lt;/strong&gt; (Terraform, Ansible), &lt;strong&gt;Cloud cost optimisation&lt;/strong&gt; (planning infra reservation), etc.
 By job titles, organisations can have different profiles like Cloud Engineer, Site Reliability Engineers, IaaC Engineer, Automation Engineer, System Administrator etc.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In my ~ 9 years of experience, my work has been a mix of &lt;strong&gt;Backend&lt;/strong&gt; and &lt;strong&gt;Devops&lt;/strong&gt;. Getting my hands dirty on Devops side has given me a lot of edge in understanding things related to deployment, cloud, servers and operating systems that other developers couldn’t easily understand. For example - whenever I was working on a new project, I had a decent idea of what memory/CPU we’d allocate to it in staging and production environment. Not only this, I use to go ahead and provision the infrastructure myself. Someone might see this negatively, specially when you have had dedicated Devops team(s) in your company. In most of the organisations, there’s a clear separation between the responsibilities of Developers and Devops. And developers never get into infra related things. In my case, there were two major reasons why I got into Devops:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://copperegg.com/&quot;&gt;My first project&lt;/a&gt; in first organisation was a monitoring product for Devops (similar to Datadog/NewRelic). When I started working on it, it was acquired by a larger company and we were mostly maintaining it. Because we were not building new features, the customer base was not growing and our sprint tasks often involved assessing current infra and downsizing the infra. Around the same time, we planned a long migration from AWS Classic to AWS VPC (it was a big deal back in 2016-17). Most of these tasks were on the Devops side and there was 1 only Devops resource allocated to us. As a result of all these activities, all the developers (we were 3 people) became Devops experts. Within 2.5 years of work, I was hands on with AWS EC2, S3, RDS, R53, VPC, SQS and Unix servers.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In my second job (&lt;a href=&quot;https://loconav.com/&quot;&gt;LocoNav&lt;/a&gt;), we did not have a dedicated Devops team for first few years. We had at max 0-1 Devops on and off, so some engineers like me (who knew cloud &amp;amp; servers) took care of the Devops side. As a result, we mentored many developers to work as Devops (while we were primarily Rails, Java and Golang Developers).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For me there is not even a thin line between Developer tasks and Devops tasks. I swiftly switch between those as needed. But rest of the developers (who are not into Devops) feel like they’re missing something. During 1:1 meetings, we’ve got this feedback from many Developers that they want to learn at least some part of Devops things we do. We encourage and guide people as needed because we feel this is a good added skill. I often see job descriptions where companies expect some understanding of Devops philosophy even from SDE candidates. Today, I’ll try to bridge the path between these two disciplines so that you have an idea on how to start.&lt;/p&gt;

&lt;h2 id=&quot;things-to-know&quot;&gt;Things to know&lt;/h2&gt;

&lt;p&gt;I’d assume you are a typical SE/SSE who is majorly writing code, writing test cases, raising pull requests and merging pull requests. You might also be using something like &lt;em&gt;Jenkins&lt;/em&gt; to build and deploy your code to an environment. You might be deploying on VMs (eg. physical / EC2), some wrapper around it (eg. Heroku / Elastic Beanstalk) or as docker containers on kubernetes (EKS / AKS / self hosted).&lt;/p&gt;

&lt;p&gt;First of all, you need &lt;strong&gt;genuine curiosity&lt;/strong&gt; to learn anything not just Devops. Here, by &lt;em&gt;curiosity&lt;/em&gt; I mean you should be curious to know:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;What happens after you click the &lt;em&gt;Build now&lt;/em&gt; button on Jenkins (for example).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What is a Jenkins project? How do we configure one?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Where do we mention the steps that execute to build a project?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Do you understand the logs (specially errors) that come in the console output of your build tool? Are you able to debug the errors or you call the Devops guy? Knowing how to interpret logs and debug issues is an underrated skill. It can take you miles ahead from others.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once you have that curiosity, you’ll try to &lt;strong&gt;look beyond code&lt;/strong&gt;. &lt;a href=&quot;https://blog.gagan93.me/asking-good-questions&quot;&gt;Ask questions&lt;/a&gt; to learn more about your overall architecture:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Which cloud provider(s) your team uses to deploy the code?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How are different components (eg. servers, databases, caches) connected to each other in a production environment? Is it different for staging, preprod or dev environment?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How does your service interact with rest of the services? Is there an architecture diagram of the system that you can refer?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Do you guys deploy on bare metal servers or cloud servers? Or do we deploy as containers?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What operating system is used to deploy your code? Even if you’re using containers, there should be one OS that is actually base image of your containers.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;By asking these questions, you’ll get to hear a lot of buzzwords like “dockers”, “AWS”, “kubernetes”, “API Gateway”. Now it depends on what you want to learn and what you want to skip. At a minimum, I’d recommend knowing something around:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;DNS / Networking&lt;/strong&gt; - &lt;em&gt;“What happen within the time when you write google.com in your browser and when the page renders on your browser window?”&lt;/em&gt;. For years, this has been my favourite interview question. I’ve asked this to all levels of engineers, and (obviously) got different level of detail in the answer. If your answer mentions DNS servers, IP resolution, proxy servers/load balancers/API gateways, Application server, request parsing, routing the request to specific handler (&lt;em&gt;controllers&lt;/em&gt; in &lt;strong&gt;MVC&lt;/strong&gt;), querying the backend (if a dynamic page), and rendering the response in the browser, then you know most of it. If not, please read about each of these things. Beyond this, you should know about basic networking like LAN (eg. your mobile/laptop are within the same network at home/office, i.e. a LAN). Also have some basic knowledge around IPv4/IPv6, &lt;a href=&quot;https://www.google.com/search?q=class+A+to+E+IP+addresses&amp;amp;oq=class+A+to+E+IP+addresses&amp;amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM1NzhqMGo3qAIAsAIA&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;IP Address classes&lt;/a&gt;, &lt;a href=&quot;https://www.tutorialspoint.com/ipv4/ipv4_reserved_addresses.htm&quot;&gt;reserved address spaces&lt;/a&gt;, etc. It will help you later understand subnets and VPC in the cloud.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cloud Provider&lt;/strong&gt; - There major ones are &lt;a href=&quot;https://aws.amazon.com/&quot;&gt;AWS&lt;/a&gt;, &lt;a href=&quot;https://azure.microsoft.com/en-in&quot;&gt;Azure&lt;/a&gt; and &lt;a href=&quot;https://cloud.google.com/&quot;&gt;GCP&lt;/a&gt;. There are many more like &lt;a href=&quot;https://www.linode.com/&quot;&gt;Linode&lt;/a&gt;, &lt;a href=&quot;https://try.digitalocean.com/&quot;&gt;DigitalOcean&lt;/a&gt;, &lt;a href=&quot;https://www.heroku.com/&quot;&gt;Heroku&lt;/a&gt; and newer ones like &lt;a href=&quot;https://vercel.com/&quot;&gt;Vercel&lt;/a&gt; and &lt;a href=&quot;https://www.netlify.com/&quot;&gt;Netlify&lt;/a&gt;. On a fundamental level, they all started with the same thing - providing you an easy way to provision a computer (i.e. a server) with required RAM, CPU, Disk and networking. Later, they evolved into more sophisticated platforms, providing variety of servers based on use case like general compute, memory heavy tasks, gaming, machine learning, etc. Beyond this, nowadays they also provide managed SQL/NoSQL databases, email service, DNS management, API Gateways, Docker image repositories, managed kubernetes service and practically everything you would need to run a medium-large app on the cloud. AWS alone provides 200+ managed services in the cloud 🤯.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Data-centers, regions and lags&lt;/strong&gt; - Let’s assume that most of your customers are in India and your servers are also in India. By India, I mean your servers are either physically managed by you in a datacenter, or are running on a managed provider like &lt;a href=&quot;https://aws.amazon.com/blogs/aws/now-open-aws-asia-pacific-mumbai-region/&quot;&gt;AWS in mumbai&lt;/a&gt; or &lt;a href=&quot;https://www.digitalocean.com/blog/introducing-our-bangalore-region-blr1&quot;&gt;DigitalOcean in Bangalore&lt;/a&gt;. Here, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_to_first_byte&quot;&gt;TTFB&lt;/a&gt; and overall request will be fast, in an ideal scenario where other factors like server load and network congestion are low. Incase your customers are in India and servers run in Singapore, then it will be slightly slower. Similarly, if you go even far and move your servers to North America, then the request latency can increase. I think you got a basic idea of physical distance here but this is more related to DNS hops. Cloud providers provision a server for you in a specific region chosen by you (eg. Mumbai). Even in Mumbai, they will not have a single data center. So they can allow you to choose a specific data center (AWS calls them &lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-availability-zones&quot;&gt;availability zones&lt;/a&gt;) where you want to run your server. If two servers are running within the same data center, the network transfer speed among them will be maximum. But this doesn’t mean that you should run all your API servers and databases in a single data center because if one data center goes down (&lt;a href=&quot;https://www.reddit.com/r/aws/comments/b90kof/how_often_does_a_region_go_down_what_about_azs/&quot;&gt;although rare&lt;/a&gt;), your entire application will go down. From a stability and fault tolerance perspective, these cloud providers isolate the regions from each other completely.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Build and Deployment process&lt;/strong&gt; - For many developers, deployment process is magical and “just happens”.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Learn what happens during build and deployment of your app. Based on the size/complexity, this can take some time to dive deep but trust me, you’ll learn &lt;strong&gt;a lot&lt;/strong&gt; in this process.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Understand what are the artifacts (output) of your build process. If it’s a Java project, you’ll possibly get a JAR/WAR file after the build is complete. For a Golang project, you’ll get a executable binary. For interpreted ones like Python and Ruby, your raw code is the artifact. This could be docker image (irrespective of the tech stack) if you’re building docker images and deploying them to swarm/kubernetes.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learn about your build tool. &lt;a href=&quot;https://www.jenkins.io/&quot;&gt;Jenkins&lt;/a&gt; is a widely used build tool. If you’re also using this, learn how to create projects, understand what is a build script, learn about pipelines, read about jenkins slaves and farms.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Containerisation technologies&lt;/strong&gt; - Everyone is doing micro-services these days (although that &lt;a href=&quot;https://adevait.com/software/why-most-startups-dont-need-microservices-yet&quot;&gt;might not be the best choice&lt;/a&gt; if you’re a startup). In a micro-services architecture, the teams are free to choose their own tech stack to develop services. While it gives you this freedom, it makes hard to choose and manage the deployment tooling. Containerisation technologies streamline the build and release process for multiple technology stacks. For example, Docker provides standardised containerisation framework for applications, while Docker Swarm / Kubernetes offer orchestration to efficiently manage deployment, scaling, and communication across services. Knowing these technologies would help you to write efficient Dockerfiles, &lt;a href=&quot;https://blog.gagan93.me/optimising-docker-builds&quot;&gt;create optimised images&lt;/a&gt; and write helm charts. These things will help to take new projects beyond the dev environment.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Operating system knowledge&lt;/strong&gt; - It’s important to have knowledge of the specific OS where your apps get deployed. Here I’m not focussing on core OS concepts like mutex, semaphores or process scheduling. We should have operational knowledge of the OS so that we can easily debug issues as required. For example, we’ve been deploying our apps on Debian (Unix) for years. So we have a decent idea around &lt;a href=&quot;https://systemd.io/https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/chap-managing_services_with_systemd&quot;&gt;systemd&lt;/a&gt;, &lt;a href=&quot;https://www.techtarget.com/searchdatacenter/definition/crontab&quot;&gt;crontabs&lt;/a&gt;, &lt;a href=&quot;https://www.sumologic.com/syslog/&quot;&gt;syslog&lt;/a&gt;, &lt;a href=&quot;https://unix.stackexchange.com/questions/545083/auth-log-entries-how-do-you-interpret-this-log&quot;&gt;authlog&lt;/a&gt;, &lt;a href=&quot;https://wiki.debian.org/Apt&quot;&gt;apt&lt;/a&gt; (our package manager), &lt;a href=&quot;https://neo4j.com/developer/kb/linux-out-of-memory-killer/&quot;&gt;OOM&lt;/a&gt; and bunch of unix commands that ease our debugging. Without this knowledge, you’d want someone to hold your hand while debugging a server issue.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Observability&lt;/strong&gt; - Let’s assume you wrote a module that has bunch of REST APIs integrated with mobile and web apps. The product was initially rolled out to 100 users, then 1000, and finally to everyone (say 1 million users). With time you’d see that some API calls fail with HTTP 500 due to an edge case that was never thought of. Once 10K entries are made in a SQL table, you might see a query slowing down because you forgot to add an index on specific table column and initially the data was not large enough to cause slowness. While debugging some cases, you’d need exact request parameters that came in a POST request to see what caused it to fail. And once there are 100 request per second, you will find a need to add more servers for your service. With system architectures becoming more distributed and on cloud, there’s a need to be able to measure internal state of the system based on external inputs like logs, metrics and traces. This comes under &lt;em&gt;Observability.&lt;/em&gt; Coming back to the specific examples: you would need an &lt;strong&gt;error reporting&lt;/strong&gt; tool like Bugsnag/Sentry, to see the class/method/line where your code failed. You should have an &lt;strong&gt;APM tool&lt;/strong&gt; like Datadog/NewRelic to see if some API calls or database queries are slowing down recently. It’s important to have &lt;strong&gt;centalized logging tools&lt;/strong&gt; (like ELK/Scalyr) in a distributed environment so that we can trace a request that routes through different micro-services to process a request. Similarly, &lt;strong&gt;infrastructure monitoring&lt;/strong&gt; tools like Prometheus are important to have a high-level overview of your servers/containers. Observability is a very wide topic, and while all this sounds overwhelming, it is actually very easy to understand if you really get the core of the problem. For example, if we don’t integrate an error reporting tool, how would we know what part of code is failing and on what line of code? Each tool solves a problem that might or might not be important to you based on needs of your product but it’s important to know broadly what all tools exist.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;There are more things I can talk about (like IaaC) but I think this much should be good to start with. The best way to learn anything is to be hands-on. I’d suggest the following ways to get your hands dirty:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Open source tools&lt;/strong&gt; (includes Jenkins, Grafana, Prometheus, Docker, Kubernetes, etc.) - All these tools are &lt;a href=&quot;https://en.wikipedia.org/wiki/Free_and_open-source_software&quot;&gt;FOSS&lt;/a&gt; and can be easily downloaded on your local machine. These are not heavy and many of them (eg. first three) come as docker images so you can uninstall them without bloating your machine.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cloud Platforms&lt;/strong&gt; - Most of the cloud providers have free-tier (eg. &lt;a href=&quot;https://aws.amazon.com/free&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;https://cloud.google.com/free/docs/free-cloud-features&quot;&gt;2&lt;/a&gt;, &lt;a href=&quot;https://azure.microsoft.com/en-in/pricing/offers/ms-azr-0044p&quot;&gt;3&lt;/a&gt;) so that you can learn things by doing (that’s the best way I believe). Aim towards learning 3-4 specific services than randomly trying out services. Keep budget alerts so that you don’t accidentally hit a &lt;a href=&quot;https://www.youtube.com/watch?v=N6lYcXjd4pg&quot;&gt;cloud overflow&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Other Platforms&lt;/strong&gt; - Almost all the platforms have free tier where they won’t charge you unless you’re pushing a lot of data (eg. a lot of traces to NewRelic or a lot of errors to Bugsnag, or many GBs of log data to Scalyr). Even they want people to use their platform so they encourage such free plans. Otherwise they at least have 15-30 day trial plans. Wherever you put your credit card, make sure your to setup some budget alert and remove the card after you are done practising. To avoid any mistakes that can cost you some dollars, concentrate and learn 1-2 things rather than picking 10 things at once.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Gagandeep Singh</name></author><category term="Devops" /><category term="Cloud" /><category term="Developers" /><summary type="html">In my ~ 9 years of experience, my work has been a mix of Backend and Devops. Getting my hands dirty on Devops side has given me a lot of edge in understanding things related to deployment, cloud, servers and operating systems that other developers couldn't easily understand. For example...</summary></entry><entry><title type="html">Optimising docker builds</title><link href="https://gagan93.me/blog/2024/02/28/optimising-docker-builds.html" rel="alternate" type="text/html" title="Optimising docker builds" /><published>2024-02-28T00:00:00+05:30</published><updated>2024-02-28T00:00:00+05:30</updated><id>https://gagan93.me/blog/2024/02/28/optimising-docker-builds</id><content type="html" xml:base="https://gagan93.me/blog/2024/02/28/optimising-docker-builds.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2024-02-28-dockers.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-by-ian-taylor-on-unsplash&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@carrier_lost?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Ian Taylor&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/blue-and-red-cargo-ship-on-sea-during-daytime-jOqJbvo1P9g?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;This month I worked on optimising docker build for an app. But before delving into the specifics of my optimisation efforts, let me provide you with a overview of the application:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;It’s a medium size, fullstack Rails application (400+ models)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It has 300+ dependencies (a.k.a ruby gems).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It contains rails views (activeadmin majorly) and assets.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It uses react on the frontend and uses webpacker to transpile those into JS.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We had two dockerfiles - one for the web app and one for background job processor (&lt;a href=&quot;https://github.com/sidekiq/sidekiq&quot;&gt;sidekiq&lt;/a&gt;, similar to &lt;a href=&quot;https://docs.celeryq.dev/en/stable/getting-started/introduction.html&quot;&gt;celary&lt;/a&gt;, &lt;a href=&quot;https://github.com/jobrunr/jobrunr&quot;&gt;jobrunr&lt;/a&gt;, etc). These could be combined now to some extent but were different due to different base images initially.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We can think of optimising a docker image in two ways:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;☑&lt;/strong&gt; Optimising build time.
&lt;strong&gt;☑&lt;/strong&gt; Optimising image size.&lt;/p&gt;

&lt;p&gt;I had to tick both the boxes and optimise as much as possible in the next few days. The first and very obvious step was to understand the steps in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; and read some good blogs on how people have been doing it for their app. I had already been reading this &lt;a href=&quot;https://diamol.net/&quot;&gt;excellent book&lt;/a&gt; earlier this month, that helped me build strong fundamentals around Docker as a technology. The first part of this book talks about the very basic things (needed to build and optimise images), while rest of the parts talk about operating Docker. While there were some excellent case studies talking specifically about optimising for Rails apps, most of the techniques were already applied back in 2022 when I picked the optimisation activity for the first time. To make sure that you get the most out of this post, I’ll share the older optimisations also.&lt;/p&gt;

&lt;h2 id=&quot;the-basics&quot;&gt;The basics&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Understanding layering&lt;/strong&gt; - A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; typically starts with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; instruction that points to a base image specific to your language/framework. Beyond this, there are many more instructions like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARG&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENV&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RUN&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ADD&lt;/code&gt;. It generally ends with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENTRYPOINT&lt;/code&gt; &amp;amp; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CMD&lt;/code&gt; instructions (unless we’re passing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CMD&lt;/code&gt; from outside). The instructions that actually create heavy layers are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RUN&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; &amp;amp; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ADD&lt;/code&gt; because we run some commands or copy some files/directories from the host machine to the docker image using these commands. From an optimisation perspective, “least changing layers should remain on top and most changing layers should be at the bottom”. This is because when you run the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker build&lt;/code&gt; command multiple times and if you haven’t cleared the build caches, the unchanged layers do not get computed again and subsequent builds are faster. This is the single most useful concept I used multiple times to get most out of caching.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Understanding base images&lt;/strong&gt; - Our app used ruby 2.5.9 so we used the &lt;a href=&quot;https://hub.docker.com/layers/library/ruby/2.5.9/images/sha256-0ed9d1839df4d5c08c98a0a7315519694c5da80b0885d6a5b96d5d5bb564d5a5?context=explore&quot;&gt;official ruby 2.5.9 image&lt;/a&gt; as our base image to start with. Digging deep on the tags, we found that there are multiple tags for the same version also (like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;slim&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpine&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;buster&lt;/code&gt;, etc). Some of these have a different unix flavour as the base OS, while some of these have less system packages installed. For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpine&lt;/code&gt; is the lightest image but it uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpine linux&lt;/code&gt; as the base operating system. We did not move to it as we have always ran our app on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;debian&lt;/code&gt; unix (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ubuntu&lt;/code&gt; mostly). In the end we settled for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;slim&lt;/code&gt; version of the image that uses debian as the base OS but doesn’t bloat the image with a lot of pre-installed packages. Someone &lt;a href=&quot;https://github.com/rails/rails/issues/46855&quot;&gt;opened an issue&lt;/a&gt; on Rails official repo that has a detailed discussion on how these images are different and what native packages we generally need to run our apps.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Understanding docker stages&lt;/strong&gt; - A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; can contain multiple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; instructions where each of them starts another “stage”. This small yet powerful concept allows you to optimize your build size by copying only required things from one stage to another stage. We’ll discuss it in detail below.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Understanding caching&lt;/strong&gt; - Docker allows caching in multiple ways. As mentioned in the first point, docker caches all the layers so that unchanged layers are not rebuilt on subsequent runs. Docker also allows caching steps of some intermediate layers so that those are not computed again from scratch. This can be done using cache mounts. Docker’s &lt;a href=&quot;https://docs.docker.com/build/guide/mounts/#add-a-cache-mount&quot;&gt;official explanation&lt;/a&gt; of cache mounts is excellent. Another small optimisation on layering can be done using &lt;a href=&quot;https://docs.docker.com/build/guide/mounts/#add-bind-mounts&quot;&gt;bind mounts&lt;/a&gt; where you can skip a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; instruction incase you need files to just run an intermediate step.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I hope the above helped in building some ground. Sharing the actual details below.&lt;/p&gt;

&lt;h2 id=&quot;our-final-dockerfiles&quot;&gt;Our final Dockerfiles&lt;/h2&gt;

&lt;p&gt;I’m pasting three Dockerfiles here as a reference. We’ll go through each line of all the three files to deeply understand why we did each change. While these are related to a Ruby on Rails fullstack application, I’ll explain this in a general context and use examples from multiple languages.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Base Dockerfile&lt;/strong&gt; - We built our own ruby-2.5.9 image on the top of the official image. The reason for doing this is - although docker’s build cache optimises a lot of steps, our build machine (a jenkins slave) periodically runs &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker system prune&lt;/code&gt; to clear old images and save disk space. And that is done because a lot of apps build their image on the build machine, eating up all the disk space. This is how the base image looks like:&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ruby:2.5.9-slim&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;apt update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; curl  &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; https://deb.nodesource.com/setup_14.x | bash - &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; gcc g++ make git nodejs &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt autoremove &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt clean &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; /var/cache/apt/archives/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; /var/lib/apt/lists/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /tmp/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /var/tmp/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;truncate&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; 0 /var/log/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;log &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;bundler:2.3.26 &lt;span class=&quot;nt&quot;&gt;--no-document&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; bundle config &lt;span class=&quot;nt&quot;&gt;--local&lt;/span&gt; without &lt;span class=&quot;s2&quot;&gt;&quot;development test&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;--mount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bind&lt;/span&gt;,source&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gemfile,target&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gemfile &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;nt&quot;&gt;--mount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bind&lt;/span&gt;,source&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gemfile.lock,target&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gemfile.lock &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    bundle &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--jobs&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;getconf _NPROCESSORS_ONLN&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Sidekiq dockerfile - Sidekiq is our background job processor. This file uses the above image in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; instruction, installs more dependencies and copies code&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ARG&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; BASE_IMAGE&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; $BASE_IMAGE&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; /home/app/my_app&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;--mount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bind&lt;/span&gt;,source&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gemfile,target&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gemfile &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;nt&quot;&gt;--mount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bind&lt;/span&gt;,source&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gemfile.lock,target&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gemfile.lock &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;nt&quot;&gt;--mount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bind&lt;/span&gt;,source&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;gems,target&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;gems &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    bundle &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--jobs&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;getconf _NPROCESSORS_ONLN&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; . .&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ENTRYPOINT&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [&quot;/home/app/my_app/entrypoint.sh&quot;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;WebApp dockerfile - This file uses the sidekiq dockerfile as the base image and adds frontend assets on the top of it. This one is a multistage build, where we do building assets in one stage and copy only the required artifacts to the final stage. This is done to ensure that no bloat exists in the final stage.&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ARG&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; BASE_IMAGE&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$BASE_IMAGE&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;frontend-pipeline&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;npm &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; yarn
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;yarn &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--production&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;--mount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cache,target&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/app/my_app/tmp/ &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;  &lt;span class=&quot;nt&quot;&gt;--mount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bind&lt;/span&gt;,source&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;config/database.yml.example,target&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;config/database.yml &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;  bundle &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;rake assets:precompile &lt;span class=&quot;nv&quot;&gt;DB_ADAPTER&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;nulldb &lt;span class=&quot;nv&quot;&gt;RAILS_ENV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;production &lt;span class=&quot;nv&quot;&gt;NODE_ENV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;production &lt;span class=&quot;nv&quot;&gt;NODE_OPTIONS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;--max-old-space-size=28672&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; $BASE_IMAGE&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXPOSE&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; 3000&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &amp;lt;whatever&amp;gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=frontend-pipeline /home/app/my_app/public /home/app/my_app/public&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;digging-deep&quot;&gt;Digging deep&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Why we switched to&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;slim&lt;/code&gt; &lt;strong&gt;image of ruby 2.5.9 and how it impacted us?&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;We were sure that we don’t need those 500+ system packages that are pre-installed inside 2.5.9 image. Additionally, on my macos, if I pull both the images (slim and non-slim), there is a huge difference of 82% (140MB vs 790MB).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;We knew what specific system packages we needed. Figuring this out is not hard. If your docker image is building successfully and all major features are working, you can conclude that easily. Having working experience on this repo of more than 5 years, I exactly knew what native dependencies we need here so we were able to move to slim image.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;It led to a build size reduction of about 450MB on AWS ECR (where we host the images).&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Why we built our own base image?&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;As explained above, our build machine purges docker caches regularly because of which the ruby docker image is pulled again and all the system packages are install again. This wasted roughly 3-4 minutes. Also, pulling the image from ECR should be faster than pulling from dockerhub (as build machine is on AWS).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If you check carefully, we install gems from Gemfiles in first two Dockerfiles. They point to different Gemfiles. In the first dockerfile, we use a Gemfile that has only those gems which are installed with native dependencies (and hence take time). This was done to ensure build time reduction. We save roughly a minute here. This technique can be used in all frameworks; if your package manager has some dependencies that hardly change and take time to install, move them to the base image. You might want to avoid this if you use one base image for multiple dependencies.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;We have some tooling for configuration management that is built using golang base image. That is also present in the base image. When we were not having base &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt;, that took about a minute to build in the sidekiq &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt;.
  &lt;strong&gt;Note&lt;/strong&gt;: I’ve not mentioned those lines in the Dockerfile as that tooling is proprietary. In real world, the first dockerfile is also multistage :)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;How did we make dependency installation fast?&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;All languages have some dependency manager: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bundler&lt;/code&gt; for Ruby, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip&lt;/code&gt; for Python, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maven/gradle&lt;/code&gt; for Java and so on. Modern computers are multi-core and most of the new tools have ways to utilise multiple cores for tasks that can be parallelized. We used &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--jobs&lt;/code&gt; argument to parallelize the installation for ruby’s bundler. Earlier we had hardcoded &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4&lt;/code&gt; as the number of parallel jobs. But because our build machine is large now (it can be small in future), it makes sense to get this value dynamically. Hence you see this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getconf _NPROCESSORS_ONLN&lt;/code&gt; in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bundle install&lt;/code&gt; step (this command works well in both unix and mac).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;We installed some gems like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nokogiri&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bcrypt&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oj&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pg&lt;/code&gt; in the base image because they’re built with native dependencies and take time. Also, we don’t upgrade them regularly and hence won’t need to revisit them in the base image. Due to this reason, there’s a special Gemfile for base image (different from the app’s Gemfile).&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Why did we combine many commands in a single RUN instruction?&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Because each RUN command creates a new layer and we want to minimize the number of layers. Most importantly, if we create some files in one layer and delete them in other layer, it won’t reduce the image size as docker would maintain both of these layers (even the one that added the file). In brief, if there’s a RUN command that only deletes something, it might not bring a change in size of your image. As a clever trick, we’re deleting some logs related to package installation and other system logs (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rm -rf /var/cache/apt/archives/* &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* &amp;amp;&amp;amp; truncate -s 0 /var/log/*log&lt;/code&gt; ) inside the same RUN instruction so that those are never inserted in the docker’s layer.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Why are we not copying the&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Gemfile&lt;/code&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Gemfile.lock&lt;/code&gt; &lt;strong&gt;in the image and then running the&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bundle install&lt;/code&gt; &lt;strong&gt;command?&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;We don’t need these files so we won’t copy them inside the docker’s layer. Rather, we’re using docker’s bind mounts to bind these files temporarily for the RUN instruction. You can use the same technique in other frameworks as well. For example, for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm&lt;/code&gt; based projects, you can bind &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yarn.lock&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.json&lt;/code&gt; before running the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yarn install&lt;/code&gt; command (or mount &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;requirements.txt&lt;/code&gt; before running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip&lt;/code&gt; for a python project, and so on).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;In the second Dockerfile, why we add codebase later and just bind Gemfiles first?&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Earlier, our instructions looked like this:&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  COPY Gemfile .
  COPY Gemfile.lock .
  RUN bundle install

  WORKDIR /home/app/my-app
  COPY . . # copies entire source code
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;p&gt;Now, we’re using the bind mount. But the question is same - why would we first copy files that define dependencies and copy rest of the code later. Reason is simple - There are more chances that something else in entire codebase will change than the dependencies. So if we copy everything and them run the dependency manager (bundler/maven/pip/yarn), then the cache of that layer will always be rebuilt. Whereas, if we copy package files first, there are more chances that the cached layer will be used.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Why our files don’t have a CMD defined?&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;We have multiple entry points that can run on the top of these docker images (eg. &lt;a href=&quot;https://github.com/puma/puma/&quot;&gt;puma&lt;/a&gt;, &lt;a href=&quot;https://github.com/anycable/anycable&quot;&gt;anycable&lt;/a&gt;, &lt;a href=&quot;https://github.com/sidekiq/sidekiq&quot;&gt;sidekiq&lt;/a&gt;). So we prefer to pass CMD from outside. There are multiple ways to do so based on the way you’re running the container. For example, if you’re running the image using plain &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker run&lt;/code&gt; command then just write the command to be run in CMD after this (Eg. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker run -it ruby:2.5.9-slim irb)&lt;/code&gt; . Similarly, you can provide CMD argument through docker-compose, docker-swarm or through helm charts (for kubernetes).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;There are many special things happening in asset precompile step. I’ll explain them one by one&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;We mount a sample &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;database.yml&lt;/code&gt; file (dummy database configuration file, doesn’t contain any credentials) using bind mounts because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rake&lt;/code&gt; commands sets up entire rails environment and that is needed.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;To make sure database is not connected, we also use a &lt;a href=&quot;https://github.com/nulldb/nulldb&quot;&gt;special library&lt;/a&gt; during precompile step.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;We use docker’s cache mounts (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--mount=type=cache&lt;/code&gt;) to cache the results of this step so that next time only changed steps get recomputed.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;We supply specific &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NODE_OPTIONS&lt;/code&gt; so that build machine’s memory can be utilized to compile as fast as possible.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Assets are compiled in an intermediate stage and only required artifacts are copied to the final layer.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;The results in our case were outstanding, specially in terms of image size. Image time did improve when I did optimizations in 2022, but this time there was no drastic increase. Time for numbers 🎉&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Build size&lt;/strong&gt;: Earlier we were maintaining two docker images - 2.4G and 1.5G. So on any node in the kubernetes nodepool, if both of our images are needed, we were required to download ~ 4G of files. Only common thing among these two was the ruby base image. So probably we were downloading ~ 3.5G if we take that out. After optimization, the image size was 1.1G and 1.5G. More importantly, this 1.1G was common as one image was used in second image. So technically, we’ll be downloading only 1.5G on any node where we need both the images. That’s an improvement of &lt;strong&gt;over 57%.&lt;/strong&gt; And this difference is only of our current optimization. If we compare it back to 2022, the difference was even large.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Build time&lt;/strong&gt;: The current build time is 12-15min. A month ago it was around 14-18min. Back in 2022, it was about 30min. So from that time it has been a significant improvement but comparing from last month, the build time has not improved much. A major time goes into transpiling react code to JS, and pushing images to ECR.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;impact&quot;&gt;Impact&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Build size&lt;/strong&gt;: At LocoNav, we have staging, preprod and production environments. We have our oldest production environment (on AWS) and few small production deployments in other countries where we operate on some other cloud providers. On AWS, we deploy daily but in other clusters we deploy weekly or fortnightly. Because we’re copying docker images from AWS ECR to other cloud providers, reduction of &amp;gt;50% would mean faster image pulls and faster deployments. In the long run, because we’re pushing lesser GBs from the build machine to ECR, and from ECR to EKS (and even outside AWS), it would lead to lesser S3 cost (for storing images) and lesser network transfer cost.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Build time&lt;/strong&gt;: As developers build and deploy multiple times to staging environment(s), shorter build times encourage them to iterate faster and not lose context of things. When build times were higher, developers often switched to other tasks after triggering builds.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;bonus&quot;&gt;Bonus&lt;/h2&gt;

&lt;p&gt;There’s a very nice tool that helps to analyze docker images layer-by-layer. Although it didn’t help me a lot to reduce the size, it was a good experience diving deeply into layers. It’s known as &lt;a href=&quot;https://github.com/wagoodman/dive&quot;&gt;dive&lt;/a&gt; and it’s an open source tool that you can install on your machine to analyze any docker image. It also made me understand how docker ignores the intermediate stages of a multi-stage build and just copies the artifacts.&lt;/p&gt;

&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing thoughts&lt;/h2&gt;

&lt;p&gt;Docker build time/size reduction is an interesting activity. There are some thumb rules (like moving less changing layers above) and some experimentation according to your app’s setup. You need to experiment a lot to understand what works for you. If you have a similar experience, or any suggestions on the above - please do comment.&lt;/p&gt;</content><author><name>Gagandeep Singh</name></author><category term="Docker" /><category term="Optimization" /><category term="Dockerfile" /><summary type="html">A detailed post on optimising docker build time and image size for any application based on my experience in optimising the same twice for one of our mid size application</summary></entry><entry><title type="html">Cloud pricing &amp;amp; Vendor lock-ins</title><link href="https://gagan93.me/blog/2024/01/27/cloud-pricing-and-vendor-lock-ins.html" rel="alternate" type="text/html" title="Cloud pricing &amp;amp; Vendor lock-ins" /><published>2024-01-27T00:00:00+05:30</published><updated>2024-01-27T00:00:00+05:30</updated><id>https://gagan93.me/blog/2024/01/27/cloud-pricing-and-vendor-lock-ins</id><content type="html" xml:base="https://gagan93.me/blog/2024/01/27/cloud-pricing-and-vendor-lock-ins.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2024-01-27-lock-in.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-by-micah-williams-on-unsplash&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@mr_williams_photography?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Micah Williams&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/black-and-gray-code-padlock-anchored-on-chain-link-fence-selective-focus-photo-lmFJOx7hPc4?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Cloud pricing is complicated. If you are trying to optimize a cloud bill for the first time that mentions more than 10 managed services, it can take a decent time to understand how this is computed. Although most of this article will talk about pricing w.r.t AWS Cloud, most of the public clouds work like that. If I was to explain on a very high level, these are a few things that should help in understanding pricing:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;PAYG&lt;/strong&gt; (Pay as you go) - Most of the cloud providers charge in a prorated manner - i.e. if you use a service for 2 days out of 30 days and the monthly charge was $90, so you end up paying $6 only (simple maths). Since 2017, AWS shifted to &lt;a href=&quot;https://aws.amazon.com/blogs/aws/new-per-second-billing-for-ec2-instances-and-ebs-volumes/&quot;&gt;per-second billing&lt;/a&gt; for many of it’s services.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Machine size&lt;/strong&gt; - Bigger the hardware, more is the cost. For most of the cases, a machine having 4 core and 16G RAM will cost exact double of machine that has 2 core and 8G RAM. I think this is very obvious.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Commitment&lt;/strong&gt; - If you commit to use a hardware for a given period (say 1 or 3 years), you get it at a discounted price (explained &lt;a href=&quot;https://aws.amazon.com/ec2/pricing/reserved-instances/&quot;&gt;here&lt;/a&gt;). Here the downside is that even if you don’t use the hardware (after say 7 months), you still pay for the remainder period (say next 5 months) because you committed to use it. Another option allows committing a fixed usage value (read &lt;a href=&quot;https://aws.amazon.com/savingsplans/&quot;&gt;this&lt;/a&gt; to know more).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Data transfer&lt;/strong&gt; - This cost can increase if your user base is growing, depending on how much data is transferred between your application and the end user. I find data transfer as the most complex component of the bill. You can read &lt;a href=&quot;https://aws.amazon.com/blogs/architecture/overview-of-data-transfer-costs-for-common-architectures/&quot;&gt;this&lt;/a&gt; to understand more on how this works.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Kind of service&lt;/strong&gt; - Each service can have it’s own pricing component that makes sense for it. As an example:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;A load balancer like ALB / NLB has a fixed monthly cost + cost of data transferred through it (explained &lt;a href=&quot;https://aws.amazon.com/elasticloadbalancing/pricing/&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;A blob storage service like S3 bills according to storage class and obviously considers the size of data you’re storing (explained &lt;a href=&quot;https://aws.amazon.com/s3/pricing/&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;A Disk storage service like EBS has a different charge for different kinds of disk (GP2/IO1), for provisioned IOPS, etc (explained &lt;a href=&quot;https://aws.amazon.com/ebs/pricing/&quot;&gt;here&lt;/a&gt;). Additionally, a disk attached to a database service like RDS is slightly costlier than one attached to a EC2 machine.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;The above section is a very brief introduction to cloud pricing. You might have encountered new terms so I’ve attached some links that will help you understand more. In the last point, I tried to write in a &lt;em&gt;metaphorical sense&lt;/em&gt; rather than simply mentioning fancy AWS service names. That has a special motive. From an architecture perspective, we should treat a load balancer as a load balancer, and not assume that we always need “AWS Application Load Balancer”. This thought process helps in decoupling our architecture from a specific cloud provider’s service.&lt;/p&gt;

&lt;p&gt;As this might not make much sense for some readers, let me explain more. If your product uses a lot of “provider specific” services, it might be harmful for you in the long run. As an example, if your code expects a lot of AWS Services to accomplish a task, you might not be able to exit AWS anytime in future (without significant investment). At this point, you might think - &lt;strong&gt;Why would I want to exit AWS&lt;/strong&gt;?. While this is a valid question, and most of the teams would not want to invest in this (risk-taking) migration, there are a few cases I know where people have done this and are expected to save a lot of dollars in the long run. The most popular ones I know are &lt;a href=&quot;https://www.youtube.com/watch?v=vFxQyZX84Ro&quot;&gt;Dukaan&lt;/a&gt; and &lt;a href=&quot;https://world.hey.com/dhh/we-have-left-the-cloud-251760fb&quot;&gt;Basecamp&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another reason to design &lt;a href=&quot;https://www.synopsys.com/cloud/insights/cloud-native-vs-cloud-agnostic.html&quot;&gt;cloud agnostic&lt;/a&gt; systems is to be able to sell in certain markets. When &lt;a href=&quot;https://loconav.com/&quot;&gt;LocoNav&lt;/a&gt; expanded its sales beyond India, numerous markets had stringent data residency and localization laws. However, none of the prominent cloud service providers had established data centers in those countries. At that time, our infrastructure was completely on AWS but we were not completely locked-in as we had self-managed installations of a lot of things. For example, despite using Elasticache for Redis, we were also having self managed redis servers (on EC2). We knew good and bad of both the worlds. Same goes for our SQL database - While most of our postgres use-cases are on RDS, we also have large self-managed postgres installations on EC2 as well. Beyond this, we were also using load balancers and S3 from AWS heavily, but we were able to find open-source alternatives for both of these that helped us in making the architecture truly cloud agnostic. Today, although the process of setting up a new deployment is not one-click, it is doable with some effort and most importantly - possible without relying on a specific provider (AWS in our case) 😇.&lt;/p&gt;

&lt;p&gt;On the other hand, had we been deeply locked in one vendor, it would not have been possible to sell in these countries. By being cloud agnostic, I do not mean that we should manage everything on our own even if new cloud provider is providing those services. For example, we use kubernetes for deploying our containers. While we completely manage Kubernetes on our own in some small cloud providers (where we just get bare VMs), we prefer using EKS on AWS and AKS on Azure. Similarly, we use &lt;a href=&quot;https://min.io/&quot;&gt;minio&lt;/a&gt; as a self-managed option for S3 in some cloud providers but for OCI, their own object store is pretty good. The best part here is that both minio and OCI Object store have very good API compatibility with S3, so no code changes were required to work with these backends.&lt;/p&gt;

&lt;p&gt;Cloud native or cloud agnostic - both the patterns have their own merits and demerits. As an architect, I’d recommend you to stay flexible and build what suits the best for your business. Using a managed service can be easy to begin with but always remember the caveats. You can also modularize your code in a way that the outermost layer (eg. service layer for APIs) doesn’t directly interact with the innermost layer (eg. that calls the specific service). There should always be some layers of abstractions that can help you shift to a different backend easily.&lt;/p&gt;

&lt;p&gt;I hope this article gives some idea around cloud pricing and vendor lock-ins. If you have had an experience doing the same for your product, or if you have any questions around the same, please share in comments.&lt;/p&gt;</content><author><name>Gagandeep Singh</name></author><category term="cloud" /><category term="pricing" /><category term="lock-in" /><summary type="html">Cloud pricing is complicated. If you are trying to optimize a cloud bill for the first time that mentions more than 10 managed services, it can take a decent time to understand how this is computed. Although most of....</summary></entry><entry><title type="html">Information Overload</title><link href="https://gagan93.me/blog/2024/01/17/information-overload.html" rel="alternate" type="text/html" title="Information Overload" /><published>2024-01-17T00:00:00+05:30</published><updated>2024-01-17T00:00:00+05:30</updated><id>https://gagan93.me/blog/2024/01/17/information-overload</id><content type="html" xml:base="https://gagan93.me/blog/2024/01/17/information-overload.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2024-01-17-information-overload.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-from-international-careers-development&quot;&gt;Photo from &lt;a href=&quot;https://www.international-careers.com/en/information-overload-memory-data-and-multitasking/&quot;&gt;International Careers Development&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Human beings are lifelong learners. For a newborn, the initial learning starts in the family. Later on, many of us undergo formal schooling, although these days, homeschooling is also an option. During my school days, most of the subject learning came from textbooks referred by teachers, and the internet was not readily accessible. By the time I graduated, projectors and computers were common in classes, but the materials used by teachers were still limited. This may sound negative, but I believe it is generally beneficial at the school level because not everyone is interested in all subjects; they focus on studying only what is necessary to pass with good grades. In case someone has interest in a particular subject, they can always refer to additional materials.&lt;/p&gt;

&lt;p&gt;Learning never stops for hungry people. Books, people, life experiences, and the (infinite) internet can help you learn something new &lt;strong&gt;every single day&lt;/strong&gt;. From past few years, internet has penetrated to much larger audience including elders and less literate people. Mobile phone operating systems with excellent user experience have made this possible.&lt;/p&gt;

&lt;p&gt;During my college days when I was coding in Java, I got interested in &lt;a href=&quot;https://docs.oracle.com/javase/tutorial/uiswing/&quot;&gt;Java Swing&lt;/a&gt;. I was done with Core Java and the idea of developing desktop apps seemed exciting. I wanted to read beyond official documentation so I found a book (&lt;a href=&quot;https://www.amazon.com/_/dp/0596004087?smid=ATVPDKIKX0DER&amp;amp;_encoding=UTF8&amp;amp;tag=oreilly20-20&quot;&gt;probably this&lt;/a&gt;). I tried to purchase a hard copy but couldn’t find it in any shops near me so I decided to print the entire book from PDF (realised later that it was a stupid idea). This was around 2013-14 so assume two things: there were not many people creating youtube video tutorials, and I had an internet connection with data limits, so it was not affordable to watch videos even if they were available.&lt;/p&gt;

&lt;p&gt;Fast forward to 2024 - cloud is new normal for everything. Non-technical people understand technology much more than before. Data packs are cheap and unlimited internet is a minimal requirement, specially for WFH employees like me. But with too many available options, decision making never becomes easy. For example - 10 years ago, I wanted to learn web development using PHP during summer vacations. I joined an institute, spent 3 months and was able to create a website with decent understanding in the end. Today if someone wants to learn a similar technology, they have too many options&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Free tutorials on Youtube&lt;/strong&gt; - Here also you have plenty of options to get confused easily. More importantly, you don’t know if the author is really an expert in the subject or just a good content creator. I’ve learnt a lot from free videos (mostly conferences).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Paid courses on Udemy / similar websites&lt;/strong&gt; - I’ve taken some courses in the past. Reviews are mixed and depends on the author. Mostly these are good to get started on a subject. I took a course on elasticsearch few years ago and one on system design recently.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Reading Books&lt;/strong&gt; - These sound boring now as more interactive options are available. Although the authors here might be very expert in the subject. I’ve learnt C and Java by reading books during college days.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Build and learn&lt;/strong&gt; - This method is also very popular. You learn basics of the language or framework and then start building something. You could go through a crash course (blog/video) to learn the basics. Here, you learn a lot of things on-the-fly while building. I learnt Rails in 2015 like this. Some people like this method while some don’t. IMO, if you build something and later continue your learning formally, it is good. Otherwise you have only surface level knowledge.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are many more methods but I think you got a basic idea. Many times, people end up purchasing video courses because they’re too cheap and we think that a paid course is better than a free one. One bad part of cheap video courses is that many people (like me) never complete these courses.&lt;/p&gt;

&lt;p&gt;The above problem is known as &lt;strong&gt;Information overload&lt;/strong&gt; because despite having a lot of resources but it’s still hard to absorb meaningful content. It’s harder than before to differentiate between valuable, accurate, and relevant information with respect to less credible or irrelevant information. Although the problem looks complex, but I use these ways to solve it for myself:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Convince myself that learning takes time and I shouldn’t expect a 10 minute video to teach me a concept. It’s good only for entertainment or for introductory knowledge.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Avoid purchasing courses just because they’re cheap. And also, not to purchase courses because everyone seems to know something (very true for DSA/System design courses these days).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dedicate time for continuous learning to stay technically relevant at work. It’s not always possible to spend some time daily so plan as a weekly average.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Spend a decent time in filtering resources rather than directly consuming short content. Prefer books for deeper understanding on any subject.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Subscribe to some free newsletters to stay updated on things I like.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I’m sure you must have faced this issue. Let me know if your problems were different and how you managed to solve them in comments. Thank you for reading.&lt;/p&gt;</content><author><name>Gagandeep Singh</name></author><category term="information" /><category term="learning" /><category term="overload" /><summary type="html">Human beings are lifelong learners. For a newborn, the initial learning starts in the family. Later on, many of us undergo formal schooling, although these days, homeschooling is also an option. During my school days, most of the subject learning came from textbooks referred....</summary></entry><entry><title type="html">Multi-tasking is not so cool</title><link href="https://gagan93.me/blog/2023/12/30/multitasking-is-not-so-cool.html" rel="alternate" type="text/html" title="Multi-tasking is not so cool" /><published>2023-12-30T00:00:00+05:30</published><updated>2023-12-30T00:00:00+05:30</updated><id>https://gagan93.me/blog/2023/12/30/multitasking-is-not-so-cool</id><content type="html" xml:base="https://gagan93.me/blog/2023/12/30/multitasking-is-not-so-cool.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2023-12-30-multitasking.png&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-from-clockwise&quot;&gt;Photo from &lt;a href=&quot;https://www.getclockwise.com/blog/multitasking-impacts-productivity&quot;&gt;Clockwise&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Multitasking refers to working on more than one task at a time. Although, as per research, it is not possible for humans to truly multitask like computers, we often hear this term at work. Among engineers, it comes up when there’s more than one task assigned to them for the day. Typically, they spend a few hours (or probably minutes) on one task, then switch to another task by pausing the first one. With senior developers/managers, the degree (and expectation) of multitasking increases. If you have grown in a startup environment, you’ve likely done a lot of multitasking already (even beyond your job role).&lt;/p&gt;

&lt;p&gt;Upon joining LocoNav, one of the concerns I raised with my seniors was my struggle to dedicate ample time to a single task, as I found myself constantly juggling multiple responsibilities. There was a time when I was assigned 4 tasks (mostly coding), and all of those were “on priority” for the respective stakeholders. I remember writing long emails back in 2018/19 regarding “context switching and productivity.” I thought it’s a planning problem (somewhat it was), but it was more to do with how fast-moving startups generally operate, and my mind took some time to get habitual.&lt;/p&gt;

&lt;p&gt;Over time, I’ve had the opportunity to work in both multitasking and focused work environments. Additionally, I serve as an individual contributor or manager as needed. Given all this experience, I’ve developed some opinions around multitasking:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;If you’re given a second task when you’re already in the middle of something, make sure to leave the first task in a state that it is efficient to continue again. For example, if you’re in the middle of an investigation and it takes 1h to complete that, ask the team, “Can the second task wait for an hour?” If yes, close your investigation, log that in a comment, and then switch. Don’t just abruptly switch. Sometimes, the second task takes so long that your manager would want someone else to continue on the first time. This is efficiently possible only if they can continue from where you left (without you explaining everything on a call).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you’re almost done in your current task or need 1-2h to complete, discuss and close this task first. Unless the second task is a P0 production bug, it should be possible to push back.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multitasking productively is hard. Even with a lot of experience, we shouldn’t expect that everyone can efficiently multitask. There are people who prefer to close one task and then pick the other one. Managers need to understand this.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You can’t avoid multitasking. Even if your sprints are planned nicely, there are chances that you’ll be assigned a production bug or some other escalation. So if you’re in a team that faces such issues, don’t think that an ideal world exists. This happens almost everywhere :)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You could feel burn out in the long run if you’re multitasking regularly. This is so because your mind overworked and couldn’t rest. After work, you might not have the mental energy for anything else. I’ve experienced this personally.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Regular multitasking might put you in a situation where you don’t actually complete anything at the end of the day. All the tasks move a little bit, but nothing real gets delivered. None of the stakeholders are happy in this situation. Rather, we could have prioritised/completed 3 tasks out of 10 (for example).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Don’t just accept tasks because they’re coming to you. If you’re working with multiple teams (shared resources), you might be assigned tasks from multiple managers where one manager might not know the complexity and priority of someone else’s tasks. Pushing back some tasks works sometimes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you have so many tasks on your plate and you think you’re just jumping from one to another, you should work on prioritizing them with your manager/team. As an example:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;If you are a developer who mostly codes, try not to switch in more than 2-3 tasks.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If you are a manager (mostly delegating tasks), you can probably switch between 3-5 tasks also (depending on the complexity of tasks).&lt;/p&gt;

        &lt;p&gt;The numbers shared above are just examples. Sometimes senior engineers are working on architecture designs that require dedicating more time on a stretch. So they prefer to go on “Do Not Disturb (DND) mode” and not pick any other task. It all depends on the specific task and team setup.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Every team wants to move fast - Developers want to be as productive as possible, and managers also need tasks to be delivered sooner. Unless your role grows from a developer who has faced productivity issues, as a manager, it takes time to understand that multitasking is not everyone’s cup of tea. As a developer, it is equally important to communicate and solve your productivity issues.&lt;/p&gt;</content><author><name>Gagandeep Singh</name></author><category term="multitasking" /><category term="planning" /><category term="opinion" /><summary type="html">Multitasking refers to working on more than one task at a time. Although, as per research, it is not possible for humans to truly multitask like computers, we often hear this term at work. Among engineers, it comes up when...</summary></entry><entry><title type="html">Debugging Production downtimes</title><link href="https://gagan93.me/blog/2023/10/29/debugging-production-downtimes.html" rel="alternate" type="text/html" title="Debugging Production downtimes" /><published>2023-10-29T00:00:00+05:30</published><updated>2023-10-29T00:00:00+05:30</updated><id>https://gagan93.me/blog/2023/10/29/debugging-production-downtimes</id><content type="html" xml:base="https://gagan93.me/blog/2023/10/29/debugging-production-downtimes.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2023-10-29-debugging-production-downtimes.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-by-daniel-tausis-on-unsplash&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@greatmalinco?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Daniel Tausis&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/fireman-watering-fire-loeqHoa1uWY?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Downtime&lt;/em&gt; refers to a period when a system/service is partially or completely unavailable. Based on the criticality of service and the customers you’re serving, this can cause a loss of millions of dollars. I’ve been on the frontline for debugging and fixing such downtimes for many years. Although most of my experience covers startup tech and you might have a different setup, I still believe that the general way of solving things remains the same.&lt;/p&gt;

&lt;p&gt;Before going into details of how we can solve (or assist in solving) a downtime, let’s see a few reasons that cause downtimes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;DOS/DDOS attacks&lt;/strong&gt; - An unexpectedly large number of requests can cause systems to become slow and eventually go down.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Network glitches&lt;/strong&gt; - Changes done to security groups, route tables or other similar network layers can cause a system to be unavailable for use.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Downtime due to deployment&lt;/strong&gt; - This happens when some heavily used system (or an API endpoint) gets slow due to some recent changes that introduced slowness. Because this is heavily used, this can occupy all the available bandwidth of the app server and take it down.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cascading failures&lt;/strong&gt; - If there is a system on which your service highly depends, and that becomes too slow or goes down, then there are high chances that it will take your system down as well. We can debate on “missing timeouts” and “coupling” in this setup, but for now, let’s agree that this can cause downtime.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cross A/Z deployments/changes&lt;/strong&gt; - Sometimes, we mistakenly introduce latency by choosing a different availability zone for some latency-critical systems. The impact of such changes is noticed only when the usage scales.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;When you see an application outage, two things to do are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Fix it asap.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Retrospect and improve.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s look into these one by one&lt;/p&gt;

&lt;h2 id=&quot;understanding-and-fixing-the-issue&quot;&gt;Understanding and fixing the issue&lt;/h2&gt;

&lt;p&gt;If you don’t have a very good monitoring setup, you’ll get a text like this from your friend in the product or business team:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hey, the customer reported 503 error on the website, can you check?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Congratulations 🥳. Your journey starts now. Let’s try to navigate it together.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Check alerts&lt;/strong&gt; 🔴 - If you have some red signs already through email, chat or some other medium, you might get some idea of what’s wrong. I remember in my previous project we had a cluster of Redis servers (one master, multiple replicas) and There was an alert configured for replication lag of more than 10 seconds. Whenever someone ran a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;KEYS *something*&lt;/code&gt; command on it, we use to get plenty of alerts instantaneously. (You might be blaming the developer for not knowing that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;KEYS&lt;/code&gt; command is &lt;a href=&quot;https://redis.io/commands/keys/&quot;&gt;blocking and runs in O(n)&lt;/a&gt;, but the issue was that usage of that redis was not documented at all and most of us maintaining the project were junior engineers).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Get the right people&lt;/strong&gt; 🧑‍🤝‍🧑 - So there are two outcomes of step 1:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;You know what’s wrong and which team owns this - Get those people on call.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Or you’re not sure what is down, or if the app is a monolith - There should be some people in the team who generally debug such things. Like old engineers of the team (god bless you if you’re the one). Get them on the call.&lt;/p&gt;

        &lt;p&gt;You might want to add some experts like DevOps (if you have a dedicated team), or database experts (if the database looks like a bottleneck) from your team. Although I agree that it might be hard to get people on call at odd hours.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Someone has to lead&lt;/strong&gt; 🤵 - Probably you were the first person to notice the downtime, and someone else knows the system better than you. Let them lead if that’s the case. Although fixing this situation would need collaboration from everyone, there has to be a person who’s doing primary debugging, sharing their screen, and delegating some tasks to someone else.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Know your tools&lt;/strong&gt; 🛠️ - I’ve debugged downtimes in those situations also where we had very minimal tooling setup, but it’s good if you have at least:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;A centralized logging solution (eliminates the time required to SSH to all servers to check logs).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;An APM tool with distributed tracing (reduces the time to understand the root cause in many cases).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Basic Pod/VM monitoring (helps to understand if RAM/CPU/Network/IO is the bottleneck).&lt;/p&gt;

        &lt;p&gt;Having these tools is important, but knowing how to use them is even more important. If you’re not familiar with your tools, please learn them. Downtime is not a good time to learn about them. If you don’t have such tools, you should be hands-on with some unix commands. For eg. I’d use a combination of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tail&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awk&lt;/code&gt; commands to debug access logs if I don’t have a logging solution available. Similarly, there are commands to see running processes (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps aux&lt;/code&gt;), free memory (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;free -h&lt;/code&gt;) and disk usage (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;df -h&lt;/code&gt; ) but these won’t show you historical data which is useful for debugging.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Thinking from First Principles&lt;/strong&gt; 🤔 - Although I talk about some common issues later, anything beyond these four points would be different for different projects/architectures. Here, we need to start thinking from the very basic things we know. The following statements should help to build some understanding:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;If the database is causing issues being a bottleneck, one/more of these might be true:&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Is there some cron job or custom script running that can cause this?&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Has some table table recently exploded in size that was being used&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Are we creating an index that might have locked the entire table?&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Is this (locked) table heavily used?&lt;/p&gt;

            &lt;p&gt;To answer any such question, we’d want to see the running queries. I’ve &lt;a href=&quot;https://gist.github.com/rgreenjr/3637525&quot;&gt;bookmarked this&lt;/a&gt; years ago to debug running queries on Postgres.&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If some specific endpoint is running slow:&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Is there a specific query that is running slow here?&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Can we quickly see what we need to fix? (Maybe add an index).&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Is there any downstream service that is slow/down, causing the slowness? Can we &lt;a href=&quot;https://microservices.io/patterns/reliability/circuit-breaker.html&quot;&gt;short-circuit&lt;/a&gt; the broken downstream for a while?&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;If the reasons are complex, can we isolate the endpoint to some specific servers/pods only? This should be configurable at the Ingress/API gateway or Load balancer based on your setup.&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If a recent deployment caused slowness:&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Can we revert to the last stable release? (your releases should be backwards compatible to do this)&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If a recent infra change caused this:&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;If you’re using &lt;a href=&quot;https://www.redhat.com/en/topics/automation/what-is-infrastructure-as-code-iac&quot;&gt;IaC&lt;/a&gt;, can we revert to the last stable setup? Infra changes can cause network disruptions (eg. modifying a security group rule) and reverting the same should generally help.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If the app servers are slow due to some surge of requests:&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Can we restart the app server processes to clear the queue? (this might lead to a loss of requests unless done gracefully)&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Should we set up some rate limiting here?&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;

        &lt;p&gt;The above list can go long according to your architecture and common issues faced but we’ll stop here. The idea is that once you scope the problem to a specific section, assume minimal correctness in the system and validate everything one by one.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Debugging downtimes is a hard problem, but solving one gives much more satisfaction than any feature release 😁 (at least to me). The learning that we get only by being present in such discussions/calls is very different (and deep) as compared to regular work. As a junior engineer, you get to see how your production is set up and what are the moving parts. If you’re a senior engineer, you see how your service interacts (and depends) on other components of the system. System outages frequently highlight areas that are vulnerable and require improvement. There are even more complicated reasons (like automation) that can cause hours of downtime (like &lt;a href=&quot;https://www.youtube.com/watch?v=dsHyUgGMht0&amp;amp;t=646s&quot;&gt;Github’s 2018 outage&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I’m sure you must also have your two cents to add here. Please share your experiences in comments.&lt;/p&gt;</content><author><name>Gagandeep Singh</name></author><category term="production" /><category term="outage" /><category term="debugging" /><summary type="html">Downtime refers to a period when a system/service is partially or completely unavailable. Based on the criticality of service and the customers you're serving, this can cause a loss of millions of dollars. I've been on the...</summary></entry><entry><title type="html">Efficient Remote Teams</title><link href="https://gagan93.me/blog/2023/10/04/efficient-remote-teams.html" rel="alternate" type="text/html" title="Efficient Remote Teams" /><published>2023-10-04T00:00:00+05:30</published><updated>2023-10-04T00:00:00+05:30</updated><id>https://gagan93.me/blog/2023/10/04/efficient-remote-teams</id><content type="html" xml:base="https://gagan93.me/blog/2023/10/04/efficient-remote-teams.html">&lt;h2 style=&quot;box-shadow: rgba(0, 0, 0, 0.24) 0px 5px 3px;&quot;&gt;&lt;img src=&quot;/blog/assets/images/2023-10-04-efficient-remote-teams.jpg&quot; alt=&quot;cover-photo&quot; /&gt;&lt;/h2&gt;

&lt;h2 style=&quot;text-align: center;font-size: 0.8em&quot; id=&quot;photo-by-chris-montgomery-on-unsplash&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@cwmonty?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Chris Montgomery&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/smgTvepind4?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Just a week before the nationwide lockdown announcement in March 2020, our engineering team decided to try remote setup for one week. At that time (like many other companies), we had work from home policy for employees but only with approval. We were not sure how this idea would work out for the entire team, and everyone thought ‘&lt;em&gt;this is just temporary&lt;/em&gt;.’&lt;/p&gt;

&lt;p&gt;Fast forward to today - we are a hybrid engineering team, where more than 50% of people prefer to work from home. I prefer working from home, but I go to the office once or twice a month (if needed). Like everyone, it took us some time to create a productive remote culture. Although we might not be perfect at running remote teams, I’d like to share a few things that help run remote teams efficiently. I’d like to share two perspectives here:&lt;/p&gt;

&lt;h2 id=&quot;for-managers&quot;&gt;For managers&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Define the working hours&lt;/strong&gt; - When everyone is WFO (working from office), it’s easy to go to someone’s desk to get something done. With the flexibility of remote culture, it’s easy to lose productivity and miss deadlines because of collaboration issues. It’s good if fixed working hours work for your team, but people generally expect flexibility when it comes to remote culture. Despite the flexibility, ensure 4-5 hours overlap among everyone so that discussions can happen seamlessly. In the rest of the hours, people can continue with their deep work.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Trust your team&lt;/strong&gt; - When remote culture started, many of my friends working in other organisations told me that their workload had increased. They had to work overtime to please their managers. In extreme cases, &lt;a href=&quot;https://www.wionews.com/world/us-based-company-fired-employee-after-he-refused-to-keep-webcam-on-during-wfh-report-524353&quot;&gt;organisations tracked&lt;/a&gt; their employees during the entire 8-9 hours of the day. On the other hand, there were discussions on the internet where people were raising voices against companies that asked employees to &lt;a href=&quot;https://edition.cnn.com/2021/09/24/tech/webcams-workplace-meetings/index.html&quot;&gt;turn on cameras during virtual meetings&lt;/a&gt;. In a nutshell, this is a trust issue. Being a manager is not easy but all these are signs of an unhealthy culture. Such organisations often experience high attrition rates. Managers should know the pace of their team members and should trust them.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Team meetups&lt;/strong&gt; - People can feel disconnected while working from home. Try to set up at least one or two meetups in a year so that people know each other. This becomes more important if the team is new and members have not met each other even once. Having in-person meetups &lt;a href=&quot;https://about.gitlab.com/company/culture/all-remote/in-person/#the-importance-of-social-interaction&quot;&gt;helps bond better&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;for-everyone-including-managers&quot;&gt;For everyone (including managers)&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Working hours&lt;/strong&gt; - When it comes to working hours, be predictable rather than always available. In flexible environments, some people start work very early (like 8-9 AM) while others start late (eg. 11-12 PM). You cannot remain available from 8 AM-10 PM. So it’s better to have (almost) fixed working hours so that everyone knows when you’re available.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Respect people’s working hours&lt;/strong&gt; - This is very important. For example, I start working at 8 - 8:30 a.m. and usually log out around 5 - 6 p.m. My team knows and respects the fact that I’ll not be available for a meeting at 7 or 8 p.m., while it might be normal for someone else to be working at that time because they started around noon. This makes perfect sense because I do not schedule meetings with these people at 8:30 a.m. (for the same reason). So respect everyone’s hours and make sure you don’t trouble them outside their working hours unless necessary.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Communication&lt;/strong&gt; - When you’re working from the office, people can come to you to discuss a task or to catch up generally. But at home, you’re physically disconnected from everyone. To make sure that team members know about the status of things, it’s important to update everyone about your work. Be responsive to emails, chats, JIRA comments, or wherever you’re expected to. You can also consider creating temporary channels to track the progress of specific projects and keep everyone informed. For example, to make sure that relevant stakeholders are aware of the project’s progress, we create a temporary slack channel (that typically runs for 1 - 2 months) to keep everyone on the same page. Once the project is delivered, we archive the channel.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Planning discussions&lt;/strong&gt; - All discussions longer than 5-10 minutes should be scheduled on the calendar in a mutual free slot. And because you’d want people to respect your time, respect their time as well - &lt;strong&gt;always join meetings on time&lt;/strong&gt;. In case you are unable to join on time, communicate the same. Missing communication here can sound irresponsible and unprofessional.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Async communication and Productivity&lt;/strong&gt; - Your team can be much more productive if they know how to work async. For example, if I have two tasks at hand - one requires someone’s input and the second requires deep work, I should leave a message to the concerned person for the first task and I’d continue on the second task. Probably within the next few hours, I’ll get a response and I can continue on the first task when I want. &lt;strong&gt;Essentially&lt;/strong&gt;, &lt;strong&gt;we need to stop assuming that all our queries will be answered synchronously.&lt;/strong&gt; Once that expectation is set, you can respect the availability of others and still ensure your productivity.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;No hello policy&lt;/strong&gt; - Someone already created a small website to explain this in detail, so I’ll just &lt;a href=&quot;https://nohello.net/en/&quot;&gt;direct you there&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Set availability status when away&lt;/strong&gt; - Whenever you’re unavailable for a few hours, or on vacation, please keep everyone informed. I hope your team uses communication tools like Slack, Teams or similar. All of them have a feature called “Status” where you can set yourself unavailable with a custom message. This small change ensures that people will know your status when they’re texting you. Similarly, setting up a &lt;a href=&quot;https://support.google.com/mail/answer/25922?hl=en&amp;amp;co=GENIE.Platform%3DDesktop&quot;&gt;vacation responder&lt;/a&gt; on your email should also help other teams who communicate with you via email.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Remote work is a valuable blessing that often goes unrecognized. People save a lot of time (primarily travel time) that can be used for doing other things. I’ve been working remote for more than three and a half years now, and I don’t feel like going back to work from office. I’m able to take better care of my health and also able to spend more time with my family. However, it is important to stay flexible to be able to work from office in future, as no work setup is permanent or the best.&lt;/p&gt;

&lt;p&gt;I might have missed many points. Feel free to add them in comments. Thanks for reading this. Take care.&lt;/p&gt;</content><author><name>Gagandeep Singh</name></author><category term="efficiency" /><category term="culture" /><category term="workstyle" /><summary type="html">Just a week before the nationwide lockdown announcement in March 2020, our engineering team decided to try remote setup for one week. At that time (like many other companies), we had work from home policy for employees but...</summary></entry></feed>